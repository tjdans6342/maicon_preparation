#!/usr/bin/env python
# -*- coding: utf-8 -*-


import cv2
import numpy as np
import rospy
from cv_bridge import CvBridge
from sensor_msgs.msg import CompressedImage

from src.configs.lane_config import LaneConfig
from src.utils.image_utils import to_roi, to_bev, color_filter, get_hough_image

from collections import deque

class LaneDetector:
    def __init__(self, image_topic="/usb_cam/image_raw/compressed", config=None, error_queue=None):
        """
        LaneDetector í´ë˜ìŠ¤
        - ì´ë¯¸ì§€ êµ¬ë… ë° ì°¨ì„  ì¸ì‹ (BEV ë³€í™˜ + Hough + Sliding Window)
        - detect() í˜¸ì¶œ ì‹œ heading, offset ë°˜í™˜
        """
        self.bridge = CvBridge()
        self.image = None
        # Config ë¡œë“œ (yaml_path ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        self.cfg = config or LaneConfig()  # ì—†ìœ¼ë©´ ê¸°ë³¸ config ë¡œë“œ

        # ROS êµ¬ë…ì ë“±ë¡
        rospy.Subscriber(
            image_topic,
            CompressedImage,
            self._camera_callback,
            queue_size=1,
            tcp_nodelay=True
        )

        if error_queue == None:
            self.error_queue = {
                'heading': deque([0] * 20),
                'lat': deque([0] * 20),
            }
        else:
            self.error_queue = error_queue
            
        self.image_dict = {
            "Original": None,
            "BEV": None,
            "Filtered": None,
            "gray": None,
            "Blurred": None,
            "binary": None,
            "Canny": None,
            "Hough": None,
            "Lane Detection": None
        }

        rospy.loginfo("ğŸ“· LaneDetector subscribed to {}".format(image_topic))

    # -------------------------------------------------------
    #  ì´ë¯¸ì§€ ì½œë°±
    # -------------------------------------------------------
    def _camera_callback(self, msg):
        self.image = self.bridge.compressed_imgmsg_to_cv2(msg, desired_encoding="bgr8")

    # -------------------------------------------------------
    #  Sliding Windowë¡œ ì¤‘ì‹¬ì„  íƒì§€
    # -------------------------------------------------------
    def _lane_detection(self, hough, nwindows, width, minpix):
        h, w = hough.shape
        histogram = np.sum(hough[h // 2:, :], axis=0)
        midx = np.argmax(histogram)

        if width < 1.0:
            width = np.int(w * width)
        margin = width // 2

        window_height = h // nwindows
        nz = hough.nonzero()
        mid_lane_inds = []
        x_list, y_list = [], []

        for window in range(nwindows - 4):
            y_low = h - (window + 1) * window_height
            y_high = h - window * window_height
            x_low = midx - margin
            x_high = midx + margin

            good_inds = (
                (nz[0] >= y_low)
                & (nz[0] < y_high)
                & (nz[1] >= x_low)
                & (nz[1] < x_high)
            ).nonzero()[0]
            mid_lane_inds.append(good_inds)

            if len(good_inds) > minpix:
                midx = int(np.mean(nz[1][good_inds]))

            x_list.append(midx)
            y_list.append((y_low + y_high) / 2)

        if len(x_list) < 3:
            return None

        fit = np.polyfit(y_list, x_list, 2)

        center_x_bottom = np.polyval(fit, h)
        distance = (w / 2) - center_x_bottom # ì™¼ìª½ì´ +, ì˜¤ë¥¸ìª½ì´ -
        offset = distance / (w / 2) # 0.0 ~ Â±1.0 ìœ¼ë¡œ ì •ê·œí™”
        heading = np.arctan(fit[1])  # ê¸°ìš¸ê¸° ê·¼ì‚¬

        if center_x_bottom == 0:
            offset = 0
        
        # print("center_x_bottom:", center_x_bottom, "offset:", offset)

        self.error_queue['heading'].popleft()
        self.error_queue['lat'].popleft()

        self.error_queue['heading'].append(heading)
        self.error_queue['lat'].append(offset)

        return {
            "heading": heading, "offset": offset,
            "fit": fit, "x": x_list, "y": y_list,
            "mid_avg": np.mean(x_list)
        }

    # -------------------------------------------------------
    #  ì‹œê°í™” í•¨ìˆ˜
    # -------------------------------------------------------
    def _visualize_lane_detection(self, hough_img, x, y, fit, mid_avg, nwindows):
        """
        ì‹œê°í™” + ì„¤ëª… ì¶œë ¥ í•¨ìˆ˜
        - _lane_detection()ì˜ ê²°ê³¼ë¥¼ ì´ìš©í•´ ì°¨ì„  ê²€ì¶œ ê³¼ì •ì„ ì‹œê°í™”.
        """
        vis = cv2.cvtColor(hough_img, cv2.COLOR_GRAY2BGR)
        h, w = hough_img.shape[:2]

        nwindows = self.cfg.nwindows
        margin = self.cfg.width // 2
        window_height = int(h / nwindows)

        # ---------- (1) ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°•ìŠ¤ ì‹œê°í™” ----------
        for cx, cy in zip(x, y):
            win_yl = int(cy - window_height / 2)
            win_yh = int(cy + window_height / 2)
            win_xl = int(cx - margin)
            win_xh = int(cx + margin)
            cv2.rectangle(vis, (win_xl, win_yl), (win_xh, win_yh), (0, 255, 0), 2)

        # ---------- (2) ì¤‘ì‹¬ì  í‘œì‹œ ----------
        for cx, cy in zip(x, y):
            cv2.circle(vis, (int(cx), int(cy)), 6, (255, 0, 0), -1)

        # ---------- (3) 2ì°¨ ê³¡ì„  ì‹œê°í™” ----------
        y_plot = np.linspace(0, h - 1, h)
        x_fit = fit[0] * y_plot ** 2 + fit[1] * y_plot + fit[2]
        for i in range(1, len(y_plot)):
            cv2.line(vis,
                    (int(x_fit[i - 1]), int(y_plot[i - 1])),
                    (int(x_fit[i]), int(y_plot[i])),
                    (0, 255, 255), 3)

        # ---------- (4) í‰ê·  ì¤‘ì‹¬ì„  ì‹œê°í™” ----------
        cv2.line(vis, (int(mid_avg), 0), (int(mid_avg), h), (255, 100, 255), 2)

        return vis

    # -------------------------------------------------------
    #  ìµœì¢… detect() â€” ì™¸ë¶€ì—ì„œ í˜¸ì¶œë˜ëŠ” ë©”ì¸ í•¨ìˆ˜
    # -------------------------------------------------------
    def detect(self, image=None):
        """
        ì…ë ¥ ì´ë¯¸ì§€(BGR)ë¥¼ ë°›ì•„ ì°¨ì„ ì„ ì¸ì‹í•˜ê³  headingê³¼ offset ë°˜í™˜.
        Robot í´ë˜ìŠ¤ì—ì„œ ì£¼ê¸°ì ìœ¼ë¡œ í˜¸ì¶œë¨.
        """
        if image is None:
            image = self.image
        if image is None:
            return None

        """
            Pipeline: 
                Original 
                â†’ (ROI) â†’ BEV 
                â†’ color_filter() 
                â†’ Gray Scale: cv2.cvtColor()
                â†’ cv2.GaussianBlur() 
                â†’ cv2.thresholds() 
                â†’ cv2.Canny() 
                â†’ get_hough_image()
        """
        bev_img, _ = to_bev(
            image,
            top=self.cfg.roi_top,
            bottom=self.cfg.roi_bottom,
            margin=self.cfg.roi_margin,
            normalized=self.cfg.bev_normalized
        )
        filtered_img = color_filter(bev_img, hls_range=self.cfg.hls)
        gray_img = cv2.cvtColor(filtered_img, cv2.COLOR_BGR2GRAY)
        blur_img = cv2.GaussianBlur(gray_img, (7, 7), 5)
        _, binary_img = cv2.threshold(blur_img, self.cfg.binary_threshold[0], self.cfg.binary_threshold[1], cv2.THRESH_BINARY)
        canny_img = cv2.Canny(binary_img, 10, 100)
        hough_img = get_hough_image(
            canny_img,
            slope_threshold=self.cfg.slope_threshold, 
            min_votes=self.cfg.min_votes
        )

        # _lane_detection()ìœ¼ë¡œ ì¤‘ì‹¬ì„  ê³„ì‚°
        result = self._lane_detection(
            hough_img, 
            nwindows=self.cfg.nwindows, 
            width=self.cfg.width, 
            minpix=self.cfg.minpix
        )

        self.image_dict = {
            "Original": image,
            "BEV": bev_img,
            "Filtered": filtered_img,
            "gray": gray_img,
            "Blurred": blur_img,
            "binary": binary_img,
            "Canny": canny_img,
            "Hough": hough_img,
            # "Lane Detection": lane_detected_img
        }


        if self.cfg.display_mode:
            lane_detected_img = self._visualize_lane_detection(
                hough_img,
                x=result["x"] if result else [],
                y=result["y"] if result else [],
                fit=result["fit"] if result else [0,0,0],
                mid_avg=result["mid_avg"] if result else 0,
                nwindows=self.cfg.nwindows
            )

            self.image_dict["Lane Detection"] = lane_detected_img

            window_pos = [
                (0, 0), (600, 0), (1200, 0),
                (0, 600), (600, 600), (1200, 600),
                (0, 0), (600, 0), (1200, 0),
                (0, 600), (600, 600), (1200, 600)
            ]

            display_names = self.cfg.image_names

            # print(display_names)

            for i, name in enumerate(display_names):
                cv2.namedWindow(name)
                cv2.moveWindow(name, window_pos[i][0], window_pos[i][1])
                cv2.imshow(name, self.image_dict[name])

            cv2.waitKey(1)
        
        return result


# -------------------------------------------------------
#  ë‹¨ë… í…ŒìŠ¤íŠ¸ìš© (rosrun lane_detector.py ì‹¤í–‰ ì‹œ)
# -------------------------------------------------------
if __name__ == "__main__":
    rospy.init_node("lane_detector_test")
    detector = LaneDetector()

    rate = rospy.Rate(10)
    while not rospy.is_shutdown():
        if detector.image is not None:
            res = detector.detect()
            if res:
                rospy.loginfo("[Lane] heading={:.3f}, offset={:.1f}".format(res['heading'], res['offset']))
        rate.sleep()

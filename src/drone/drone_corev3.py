"""
ë“œë¡  ì´ë¯¸ì§€ ë¶„ì„ í†µí•© ì‹œìŠ¤í…œ
- ROI ìë¥´ê¸° ê¸°ëŠ¥
- ì´ë¯¸ì§€ ë¶„ë¥˜ ê¸°ëŠ¥
- YOLO ê°ì²´ íƒì§€ ë° ë§¤ì¹­ ê¸°ëŠ¥
- ë°±ì—… ROI ë¶„ì„ ë©”ì»¤ë‹ˆì¦˜
"""
'''
ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬ì‹œ
python drone_corev3.py path/to/image.jpg
í´ë” ë°°ì¹˜ ì²˜ë¦¬
python drone_corev3.py path/to/folder output_results.csv
ì´ê±° ê¼­ ì‹¤ì‚¬ìš©ì „ í…ŒìŠ¤íŠ¸ í•´ë´ì•¼í•¨

'''

import os
import sys
import cv2
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import logging
import torch
import torch.nn as nn
from torchvision import transforms
import torchvision.models as models
from PIL import Image
import json
from tqdm import tqdm
import csv
import time
from torch.serialization import add_safe_globals

# torchvision ë³€í™˜ í´ë˜ìŠ¤ë¥¼ ì•ˆì „í•œ ì „ì—­ìœ¼ë¡œ ì¶”ê°€
add_safe_globals([
    'torchvision.transforms.transforms.Compose',
    'torchvision.transforms.transforms.Resize',
    'torchvision.transforms.transforms.ToTensor',
    'torchvision.transforms.transforms.Normalize'
])

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from target_geometry import (
        recognize_rotated_h_marker_sift,
        transform_image_from_params,
        calculate_drone_altitude_from_scale_precise,
        detect_all_building_rooftops,
        BUILDINGS_INFO,
        H_MARKER_REAL_WIDTH_M,
        TARGET_X,
        TARGET_Y
    )
    from yolo_classfier import DroneClassifier as YoloClassifier, DetectionResult
    TARGET_GEOMETRY_IMPORTED = True
except ImportError:
    print("âš ï¸ target_geometry ë˜ëŠ” yolo_classfier ëª¨ë“ˆì„ ì„í¬íŠ¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")
    TARGET_GEOMETRY_IMPORTED = False

# ========================================
# âš™ï¸ ì „ì—­ ì„¤ì •
# ========================================

# ROI ì„¤ì •
CROP_SIZE_PIXELS = 250  # ì˜ë¼ë‚¼ ROIì˜ í¬ê¸°
OUTPUT_BASE_DIR = "src/drone/second"  # ì €ì¥í•  ê¸°ë³¸ ë””ë ‰í† ë¦¬

# ê±´ë¬¼ ë§¤ì¹­ ê±°ë¦¬ ì„ê³„ê°’ (í”½ì…€)
MATCHING_DISTANCE_THRESHOLD = 200.0  # ê¸°ë³¸ê°’ 200px

# ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°
ORIGINAL_IMAGE_WIDTH = 4000
ORIGINAL_IMAGE_HEIGHT = 3000

# YOLO ì…ë ¥ í¬ê¸°
YOLO_INPUT_SIZE = 640

# ========================================
# ğŸ–¼ï¸ ROI ìë¥´ê¸° ë° ì €ì¥ í•¨ìˆ˜
# ========================================

def crop_rois_for_classification(
    transformed_image: np.ndarray,
    rooftop_positions: dict[int, tuple[float, float]],
    image_index: str,
    crop_size: int = CROP_SIZE_PIXELS,
    output_base_dir: str = OUTPUT_BASE_DIR
) -> Dict[int, str]:
    """
    ì •ë ¬ëœ ì´ë¯¸ì§€ì—ì„œ ê³„ì‚°ëœ ì˜¥ìƒ ìœ„ì¹˜ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ROIë¥¼ ì˜ë¼ë‚´ì–´ ì €ì¥í•©ë‹ˆë‹¤.
    ê° ROIëŠ” 'output_base_dir/ê±´ë¬¼ID/ì´ë¯¸ì§€ì¸ë±ìŠ¤_ê±´ë¬¼ID.png' í˜•íƒœë¡œ ì €ì¥ë©ë‹ˆë‹¤.
    
    Args:
        transformed_image (np.ndarray): H ë§ˆì»¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ëœ ì´ë¯¸ì§€.
        rooftop_positions (dict[int, tuple[float, float]]): 
            {ê±´ë¬¼ID: (ì˜¥ìƒ X ì¢Œí‘œ, ì˜¥ìƒ Y ì¢Œí‘œ)} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬.
        image_index (str): ì €ì¥í•  íŒŒì¼ëª…ì— ì‚¬ìš©ë  ê³ ìœ  ì¸ë±ìŠ¤ (ì˜ˆ: '13', '20', 'test').
        crop_size (int): ì˜ë¼ë‚¼ ROIì˜ í•œ ë³€ ê¸¸ì´ (í”½ì…€).
        output_base_dir (str): ROIë¥¼ ì €ì¥í•  ê¸°ë³¸ ë””ë ‰í† ë¦¬ ì´ë¦„.
        
    Returns:
        Dict[int, str]: {ê±´ë¬¼ID: ROI íŒŒì¼ ê²½ë¡œ} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    
    # ì´ë¯¸ì§€ í¬ê¸°
    h, w = transformed_image.shape[:2]
    half_size = crop_size // 2
    
    # ê¸°ë³¸ ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    if not os.path.exists(output_base_dir):
        os.makedirs(output_base_dir)
        print(f"ê¸°ë³¸ ë””ë ‰í† ë¦¬ ìƒì„±: {output_base_dir}")

    # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (ê±´ë¬¼ID: ROI íŒŒì¼ ê²½ë¡œ)
    roi_paths = {}

    # ê° ê±´ë¬¼ë³„ ROI ìë¥´ê¸° ë° ì €ì¥
    for building_id, (center_x_float, center_y_float) in rooftop_positions.items():
        center_x = int(round(center_x_float))
        center_y = int(round(center_y_float))
        
        # 1. ìë¥¼ ì˜ì—­ì˜ ê²½ê³„ ê³„ì‚°
        x_min = center_x - half_size
        x_max = center_x + half_size
        y_min = center_y - half_size
        y_max = center_y + half_size
        
        # 2. ì´ë¯¸ì§€ ê²½ê³„ ì²˜ë¦¬ ë° ìë¥´ê¸°
        # Crop ì˜ì—­ì´ ì´ë¯¸ì§€ ë°–ìœ¼ë¡œ ë‚˜ê°€ì§€ ì•Šë„ë¡ ì¡°ì •
        crop_x_min = max(0, x_min)
        crop_y_min = max(0, y_min)
        crop_x_max = min(w, x_max)
        crop_y_max = min(h, y_max)
        
        # ì´ë¯¸ì§€ ìë¥´ê¸° (ROI ì¶”ì¶œ)
        cropped_roi = transformed_image[crop_y_min:crop_y_max, crop_x_min:crop_x_max]
        
        # 3. ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„± (ì˜ˆ: src/drone/second/1, ...)
        save_dir = os.path.join(output_base_dir, str(building_id))
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)
            
        # 4. íŒŒì¼ ì €ì¥
        # íŒŒì¼ëª…ì— image_indexë¥¼ ì‚¬ìš©í•˜ì—¬ ê³ ìœ ì„± í™•ë³´
        save_path = os.path.join(save_dir, f"{image_index}_B{building_id}.png")
        cv2.imwrite(save_path, cropped_roi)
        print(f"ê±´ë¬¼ {building_id} ROI ì €ì¥ ì™„ë£Œ: {save_path} (í¬ê¸°: {cropped_roi.shape[1]}x{cropped_roi.shape[0]})")
        
        # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ì— ì¶”ê°€
        roi_paths[building_id] = save_path
        
    return roi_paths

# ========================================
# ğŸ¤– ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ í´ë˜ìŠ¤
# ========================================

class DroneClassifier(nn.Module):
    def __init__(self, num_classes=2, pretrained=False):
        super(DroneClassifier, self).__init__()
        
        # EfficientNet-B0 ë°±ë³¸ ì‚¬ìš©
        self.backbone = models.efficientnet_b0(pretrained=pretrained)
        
        # ë¶„ë¥˜ê¸° ë¶€ë¶„ ìˆ˜ì •
        num_features = self.backbone.classifier[1].in_features
        self.backbone.classifier = nn.Sequential(
            nn.Dropout(0.3),
            nn.Linear(num_features, 512),
            nn.ReLU(),
            nn.BatchNorm1d(512),
            nn.Dropout(0.5),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.BatchNorm1d(256),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes)
        )
        
    def forward(self, x):
        return self.backbone(x)

class DroneImageClassifier:
    def __init__(self, model_path, config_path=None, device=None):
        """
        ë“œë¡  ì´ë¯¸ì§€ ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
        
        Args:
            model_path (str): ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (.pth)
            config_path (str, optional): ì„¤ì • íŒŒì¼ ê²½ë¡œ (.json)
            device (str, optional): ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ('cuda' ë˜ëŠ” 'cpu')
        """
        self.device = device if device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}")
        
        # ì„¤ì • íŒŒì¼ ë¡œë“œ
        if config_path is None:
            config_path = model_path.replace('.pth', '_config.json')
        
        if os.path.exists(config_path):
            with open(config_path, 'r') as f:
                self.config = json.load(f)
        else:
            # ê¸°ë³¸ ì„¤ì •
            self.config = {
                'img_size': 224,
                'class_names': ['OK', 'NG'],
                'model_type': 'EfficientNet-B0'
            }
            print(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        # ë³€í™˜ ì •ì˜
        self.transform = transforms.Compose([
            transforms.Resize((self.config['img_size'], self.config['img_size'])),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = DroneClassifier(num_classes=len(self.config['class_names']), pretrained=False)
        
        try:
            # ë¨¼ì € weights_only=Trueë¡œ ì‹œë„ (ë” ì•ˆì „í•œ ë°©ë²•)
            checkpoint = torch.load(model_path, map_location=self.device)
            self.model.load_state_dict(checkpoint['model_state_dict'])
        except Exception as e:
            print(f"weights_only=Trueë¡œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("weights_only=Falseë¡œ ì‹œë„í•©ë‹ˆë‹¤. ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì¸ ê²½ìš°ì—ë§Œ ì§„í–‰í•˜ì„¸ìš”.")
            
            # weights_only=Falseë¡œ ì‹œë„ (ë³´ì•ˆ ìœ„í—˜ì´ ìˆì§€ë§Œ ì´ì „ ë²„ì „ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´)
            checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
            self.model.load_state_dict(checkpoint['model_state_dict'])
        
        self.model.to(self.device)
        self.model.eval()
        
        print(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        print(f"í´ë˜ìŠ¤: {self.config['class_names']}")
    
    def predict_image(self, image_path):
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ë¥˜
        
        Args:
            image_path (str): ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            tuple: (ì˜ˆì¸¡ í´ë˜ìŠ¤ ì¸ë±ìŠ¤, ì˜ˆì¸¡ í´ë˜ìŠ¤ ì´ë¦„, ì‹ ë¢°ë„ ì ìˆ˜)
        """
        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
        try:
            image = Image.open(image_path).convert('RGB')
            input_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            # ì˜ˆì¸¡
            with torch.no_grad():
                output = self.model(input_tensor)
                probabilities = torch.nn.functional.softmax(output, dim=1)[0]
                
            # ê²°ê³¼ í•´ì„
            pred_idx = torch.argmax(probabilities).item()
            pred_class = self.config['class_names'][pred_idx]
            confidence = probabilities[pred_idx].item() * 100
                
            return pred_idx, pred_class, confidence
            
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ë¶„ë¥˜ ì˜¤ë¥˜ ({image_path}): {e}")
            return None, None, None
    
    def predict_folder(self, folder_path, output_csv='results.csv'):
        """
        í´ë” ë‚´ ëª¨ë“  ì´ë¯¸ì§€ ë¶„ë¥˜
        
        Args:
            folder_path (str): ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
            output_csv (str): ê²°ê³¼ë¥¼ ì €ì¥í•  CSV íŒŒì¼ ê²½ë¡œ
            
        Returns:
            dict: ë¶„ë¥˜ ê²°ê³¼ (íŒŒì¼ëª…: (í´ë˜ìŠ¤, ì‹ ë¢°ë„))
        """
        results = {}
        image_files = []
        
        # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
        for root, _, files in os.walk(folder_path):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):
                    image_files.append(os.path.join(root, file))
            
        print(f"ì´ {len(image_files)}ê°œ ì´ë¯¸ì§€ ë¶„ë¥˜ ì‹œì‘...")
        
        # ê° ì´ë¯¸ì§€ ë¶„ë¥˜
        for image_path in tqdm(image_files):
            pred_idx, pred_class, confidence = self.predict_image(image_path)
            if pred_class:
                results[image_path] = (pred_class, confidence)
        
        # ê²°ê³¼ ìš”ì•½
        ok_count = sum(1 for _, (cls, _) in results.items() if cls == 'OK')
        ng_count = sum(1 for _, (cls, _) in results.items() if cls == 'NG')
        
        print(f"\në¶„ë¥˜ ê²°ê³¼:")
        print(f"OK: {ok_count}ê°œ ({ok_count/len(results)*100:.1f}%)")
        print(f"NG: {ng_count}ê°œ ({ng_count/len(results)*100:.1f}%)")
        
        # CSV ì €ì¥
        with open(output_csv, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['íŒŒì¼ëª…', 'ë¶„ë¥˜ ê²°ê³¼', 'ì‹ ë¢°ë„(%)'])
            for image_path, (pred_class, confidence) in results.items():
                writer.writerow([image_path, pred_class, f"{confidence:.2f}"])
        print(f"ê²°ê³¼ê°€ {output_csv}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        return results

# ========================================
# ğŸ¢ ê±´ë¬¼ ë§¤ì¹­ ì‹œìŠ¤í…œ
# ========================================

class BuildingMatcher:
    """íƒì§€ëœ ê°ì²´ì™€ ê±´ë¬¼ ì˜¥ìƒ ì¢Œí‘œ ë§¤ì¹­"""
    
    def __init__(
        self,
        buildings_info: Dict[int, Dict] = BUILDINGS_INFO if TARGET_GEOMETRY_IMPORTED else None,
        distance_threshold: float = MATCHING_DISTANCE_THRESHOLD
    ):
        """
        ì´ˆê¸°í™”
        
        Args:
            buildings_info: ê±´ë¬¼ ì •ë³´ ë”•ì…”ë„ˆë¦¬
            distance_threshold: ë§¤ì¹­ íŒì • ê±°ë¦¬ ì„ê³„ê°’ (í”½ì…€)
        """
        self.buildings_info = buildings_info
        self.distance_threshold = distance_threshold
        self.logger = logging.getLogger('BuildingMatcher')
        self.logger.info(f"ê±´ë¬¼ ë§¤ì¹­ê¸° ì´ˆê¸°í™”: ê±°ë¦¬ ì„ê³„ê°’ = {distance_threshold}px")
    
    def calculate_distance(
        self,
        point1: Tuple[float, float],
        point2: Tuple[float, float]
    ) -> float:
        """ë‘ ì  ì‚¬ì´ì˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°"""
        return np.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)
    
    def match_detection_to_building(
        self,
        detection_center: Tuple[float, float],
        rooftop_positions: Dict[int, Tuple[float, float]]
    ) -> Optional[Tuple[int, float]]:
        """
        íƒì§€ëœ ê°ì²´ë¥¼ ê°€ì¥ ê°€ê¹Œìš´ ê±´ë¬¼ì— ë§¤ì¹­
        
        Args:
            detection_center: íƒì§€ëœ ê°ì²´ì˜ ì¤‘ì‹¬ ì¢Œí‘œ
            rooftop_positions: ê±´ë¬¼ ì˜¥ìƒ ì¢Œí‘œ ë”•ì…”ë„ˆë¦¬ {building_id: (x, y)}
        
        Returns:
            (building_id, distance) ë˜ëŠ” None (ë§¤ì¹­ ì‹¤íŒ¨)
        """
        min_distance = float('inf')
        matched_building_id = None
        
        # ëª¨ë“  ê±´ë¬¼ê³¼ì˜ ê±°ë¦¬ ê³„ì‚°
        distances = {}
        for building_id, rooftop_pos in rooftop_positions.items():
            distance = self.calculate_distance(detection_center, rooftop_pos)
            distances[building_id] = distance
            
            if distance < min_distance:
                min_distance = distance
                matched_building_id = building_id
        
        # ê±°ë¦¬ ì •ë³´ ì¶œë ¥ (ê°€ê¹Œìš´ ìˆœìœ¼ë¡œ ì •ë ¬)
        sorted_distances = sorted(distances.items(), key=lambda x: x[1])
        self.logger.info(f"  ğŸ“ ê±´ë¬¼ë³„ ê±°ë¦¬ (ê°€ê¹Œìš´ ìˆœ):")
        for bid, dist in sorted_distances[:5]:  # ìƒìœ„ 5ê°œë§Œ
            status = "âœ…" if dist <= self.distance_threshold else "âŒ"
            self.logger.info(f"    {status} ê±´ë¬¼ {bid}: {dist:.2f}px")
        
        # ê±°ë¦¬ ì„ê³„ê°’ í™•ì¸
        if min_distance <= self.distance_threshold:
            self.logger.info(
                f"  âœ… ë§¤ì¹­ ì„±ê³µ: ê±´ë¬¼ {matched_building_id} "
                f"(ê±°ë¦¬: {min_distance:.2f}px â‰¤ {self.distance_threshold}px)"
            )
            return (matched_building_id, min_distance)
        else:
            self.logger.warning(
                f"  âŒ ë§¤ì¹­ ì‹¤íŒ¨: ê°€ì¥ ê°€ê¹Œìš´ ê±´ë¬¼ {matched_building_id}ê¹Œì§€ì˜ "
                f"ê±°ë¦¬({min_distance:.2f}px)ê°€ ì„ê³„ê°’({self.distance_threshold}px)ì„ ì´ˆê³¼"
            )
            return None
    
    def match_all_detections(
        self,
        detection_result,
        rooftop_positions: Dict[int, Tuple[float, float]]
    ) -> List[Dict]:
        """
        ëª¨ë“  íƒì§€ ê²°ê³¼ë¥¼ ê±´ë¬¼ì— ë§¤ì¹­ (ê°™ì€ ì¢Œí‘œê³„)
        
        Args:
            detection_result: YOLO íƒì§€ ê²°ê³¼
            rooftop_positions: ê±´ë¬¼ ì˜¥ìƒ ì¢Œí‘œ (ê°™ì€ ì¢Œí‘œê³„)
        
        Returns:
            ë§¤ì¹­ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        matches = []
        
        self.logger.info(f"\n{'='*80}")
        self.logger.info(f"ğŸ” ì´ {len(detection_result.detections)}ê°œ íƒì§€ ê°ì²´ ë§¤ì¹­ ì‹œì‘")
        self.logger.info(f"{'='*80}")
        self.logger.info(f"ğŸ“ ê±´ë¬¼ ì˜¥ìƒ ì¢Œí‘œ ({len(rooftop_positions)}ê°œ):")
        for bid, pos in rooftop_positions.items():
            self.logger.info(f"  ê±´ë¬¼ {bid}: ({pos[0]:.1f}, {pos[1]:.1f})")
        
        for idx, detection in enumerate(detection_result.detections, 1):
            self.logger.info(f"\n{'='*60}")
            self.logger.info(f"[{idx}/{len(detection_result.detections)}] íƒì§€ ê°ì²´ ë§¤ì¹­ ì¤‘...")
            self.logger.info(f"  í´ë˜ìŠ¤: {detection.class_name}")
            self.logger.info(f"  ì‹ ë¢°ë„: {detection.confidence:.3f}")
            
            # íƒì§€ ì¤‘ì‹¬ ì¢Œí‘œ (ë³€í™˜ëœ ì´ë¯¸ì§€ ê¸°ì¤€)
            center = (detection.bbox.center_x, detection.bbox.center_y)
            self.logger.info(f"  ğŸ“ íƒì§€ ì¤‘ì‹¬: ({center[0]:.1f}, {center[1]:.1f})")
            
            # ê±´ë¬¼ ë§¤ì¹­
            match_result = self.match_detection_to_building(center, rooftop_positions)
            
            if match_result is not None:
                building_id, distance = match_result
                
                match_info = {
                    'detection': detection,
                    'building_id': building_id,
                    'distance': distance,
                    'center': center,
                    'bbox': (detection.bbox.x1, detection.bbox.y1, 
                            detection.bbox.x2, detection.bbox.y2),
                    'rooftop_position': rooftop_positions[building_id]
                }
                matches.append(match_info)
                
                self.logger.info(
                    f"  âœ… ìµœì¢… ë§¤ì¹­: ê±´ë¬¼ {building_id} (ê±°ë¦¬: {distance:.2f}px)"
                )
            else:
                self.logger.warning(f"  âŒ ë§¤ì¹­ ì‹¤íŒ¨: ì„ê³„ê°’ ë‚´ ê±´ë¬¼ ì—†ìŒ")
        
        self.logger.info(f"\n{'='*80}")
        self.logger.info(f"âœ… ë§¤ì¹­ ì™„ë£Œ: {len(matches)}/{len(detection_result.detections)}ê°œ ì„±ê³µ")
        self.logger.info(f"{'='*80}\n")
        
        return matches

# ========================================
# ğŸš ë“œë¡  í†µí•© ì‹œìŠ¤í…œ
# ========================================

class DroneIntegratedSystem:
    """
    ë“œë¡  ì´ë¯¸ì§€ ë¶„ì„ í†µí•© ì‹œìŠ¤í…œ
    - ROI ìë¥´ê¸°
    - ì´ë¯¸ì§€ ë¶„ë¥˜
    - YOLO ê°ì²´ íƒì§€
    - ë°±ì—… ROI ë¶„ì„
    """
    
    def __init__(
        self,
        yolo_classifier: YoloClassifier,
        roi_classifier_path: str,
        h_marker_template_path: str,
        buildings_info: Dict[int, Dict] = BUILDINGS_INFO if TARGET_GEOMETRY_IMPORTED else None,
        distance_threshold: float = MATCHING_DISTANCE_THRESHOLD,
        roi_config_path: str = None
    ):
        """
        ë“œë¡  í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            yolo_classifier: YOLO ë¶„ë¥˜ê¸° ì¸ìŠ¤í„´ìŠ¤
            roi_classifier_path: ROI ë¶„ë¥˜ ëª¨ë¸ ê²½ë¡œ
            h_marker_template_path: H ë§ˆì»¤ í…œí”Œë¦¿ ì´ë¯¸ì§€ ê²½ë¡œ
            buildings_info: ê±´ë¬¼ ì •ë³´
            distance_threshold: ê±´ë¬¼ ë§¤ì¹­ ê±°ë¦¬ ì„ê³„ê°’
            roi_config_path: ROI ë¶„ë¥˜ê¸° ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        self.yolo_classifier = yolo_classifier
        self.buildings_info = buildings_info
        
        # H ë§ˆì»¤ í…œí”Œë¦¿ ë¡œë“œ
        self.h_template = cv2.imread(h_marker_template_path)
        if self.h_template is None:
            raise FileNotFoundError(f"H ë§ˆì»¤ í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {h_marker_template_path}")
        
        self.h_template_width = self.h_template.shape[1]
        
        # ê±´ë¬¼ ë§¤ì¹­ê¸° ì´ˆê¸°í™”
        self.building_matcher = BuildingMatcher(
            buildings_info=buildings_info,
            distance_threshold=distance_threshold
        )
        
        # ROI ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
        self.roi_classifier = DroneImageClassifier(
            model_path=roi_classifier_path,
            config_path=roi_config_path
        )
        
        # ë¡œê¹… ì„¤ì •
        self.logger = logging.getLogger('DroneIntegratedSystem')
        self.logger.info("âœ… ë“œë¡  í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def process_image(
        self,
        image_path: str,
        visualize: bool = True,
        save_results: bool = True,
        use_backup_roi: bool = True
    ) -> Dict:
        """
        ë“œë¡  ì´ë¯¸ì§€ ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
        
        Args:
            image_path: ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ
            visualize: ì‹œê°í™” ì—¬ë¶€
            save_results: ê²°ê³¼ ì €ì¥ ì—¬ë¶€
            use_backup_roi: YOLO ì‹¤íŒ¨ ì‹œ ë°±ì—… ROI ë¶„ì„ ì‚¬ìš© ì—¬ë¶€
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        self.logger.info(f"\n{'='*80}")
        self.logger.info(f"ğŸš ë“œë¡  ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘: {image_path}")
        self.logger.info(f"{'='*80}\n")
        
        # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
        result = {
            'success': False,
            'image_path': image_path,
            'h_marker_detected': False,
            'drone_altitude_m': None,
            'detection_result': None,
            'rooftop_positions': None,
            'matches': [],
            'roi_results': {},
            'error_message': None
        }
        
        # ì„ì‹œ íŒŒì¼ ê²½ë¡œ
        temp_path = None
        roi_paths = {}
        
        try:
            # 1. ì´ë¯¸ì§€ ë¡œë“œ
            original_image = cv2.imread(image_path)
            if original_image is None:
                result['error_message'] = f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}"
                self.logger.error(result['error_message'])
                return result
            
            self.logger.info(f"ğŸ“· ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: {original_image.shape}")
            
            # 2. H ë§ˆì»¤ ì¸ì‹
            self.logger.info("\nğŸ¯ H ë§ˆì»¤ ì¸ì‹ ì¤‘...")
            h_marker_params = recognize_rotated_h_marker_sift(
                original_image,
                self.h_template,
                min_match_count=10
            )
            
            if h_marker_params is None:
                result['error_message'] = "H ë§ˆì»¤ ì¸ì‹ ì‹¤íŒ¨"
                self.logger.error(result['error_message'])
                return result
            
            result['h_marker_detected'] = True
            self.logger.info(f"âœ… H ë§ˆì»¤ ì¸ì‹ ì„±ê³µ")
            
            # 3. ì´ë¯¸ì§€ ì •ë ¬ ë° ë“œë¡  ê³ ë„ ê³„ì‚°
            self.logger.info("\nğŸ”„ ì´ë¯¸ì§€ ì •ë ¬ ì¤‘...")
            transformed_image, transformation_matrix = transform_image_from_params(
                original_image,
                h_marker_params
            )
            
            scale_factor = h_marker_params[3]
            drone_altitude = calculate_drone_altitude_from_scale_precise(
                scale_factor,
                H_MARKER_REAL_WIDTH_M,
                self.h_template_width,
                image_width_pixels=original_image.shape[1],
                fov_horizontal_deg=118
            )
            
            result['drone_altitude_m'] = drone_altitude
            self.logger.info(f"âœ… ë“œë¡  ê³ ë„: {drone_altitude:.2f}m")
            self.logger.info(f"âœ… ë³€í™˜ëœ ì´ë¯¸ì§€ í¬ê¸°: {transformed_image.shape}")
            
            # 4. ê±´ë¬¼ ì˜¥ìƒ ì¢Œí‘œ ê³„ì‚° (ë³€í™˜ëœ ì´ë¯¸ì§€ ê¸°ì¤€)
            self.logger.info("\nğŸ¢ ê±´ë¬¼ ì˜¥ìƒ ì¢Œí‘œ ê³„ì‚° ì¤‘ (ë³€í™˜ëœ ì´ë¯¸ì§€ ê¸°ì¤€)...")
            rooftop_positions, _ = detect_all_building_rooftops(
                transformed_image,
                self.buildings_info,
                drone_altitude,
                transformation_matrix=transformation_matrix,
                original_image_shape=original_image.shape,
                visualize=False
            )
            
            result['rooftop_positions'] = rooftop_positions
            self.logger.info(f"âœ… {len(rooftop_positions)}ê°œ ê±´ë¬¼ ì˜¥ìƒ ì¢Œí‘œ ê³„ì‚° ì™„ë£Œ")
            
            # 5. ROI ìë¥´ê¸° (ë°±ì—… ë¶„ì„ìš©)
            if use_backup_roi:
                self.logger.info("\nâœ‚ï¸ ROI ìë¥´ê¸° ì¤‘...")
                # ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ìƒì„± (íŒŒì¼ëª… ê¸°ë°˜)
                image_index = Path(image_path).stem
                
                # ROI ìë¥´ê¸°
                roi_paths = crop_rois_for_classification(
                    transformed_image=transformed_image,
                    rooftop_positions=rooftop_positions,
                    image_index=image_index
                )
                self.logger.info(f"âœ… {len(roi_paths)}ê°œ ROI ìƒì„± ì™„ë£Œ")
            
            # 6. ë³€í™˜ëœ ì´ë¯¸ì§€ë¥¼ ì„ì‹œ ì €ì¥ (YOLO ë¶„ì„ìš©)
            temp_path = Path(image_path).parent / f"{Path(image_path).stem}_transformed_temp.jpg"
            cv2.imwrite(str(temp_path), transformed_image)
            self.logger.info(f"ğŸ“ ë³€í™˜ëœ ì´ë¯¸ì§€ ì„ì‹œ ì €ì¥: {temp_path}")
            
            # 7. YOLO ê°ì²´ íƒì§€ (ë³€í™˜ëœ ì´ë¯¸ì§€ì—ì„œ)
            self.logger.info("\nğŸ¤– YOLO ê°ì²´ íƒì§€ ì¤‘ (ë³€í™˜ëœ ì´ë¯¸ì§€)...")
            detection_result = self.yolo_classifier.detect_from_file(
                str(temp_path),  # â† ë³€í™˜ëœ ì´ë¯¸ì§€ ì‚¬ìš©!
                visualize=False,
                save_json=False
            )
            
            result['detection_result'] = detection_result
            self.logger.info(
                f"âœ… íƒì§€ ì™„ë£Œ: {detection_result.detection_count}ê°œ ê°ì²´ "
                f"(ì„±ê³µ: {detection_result.success})"
            )
            
            # 8. íƒì§€ ê°ì²´ì™€ ê±´ë¬¼ ë§¤ì¹­ (ê°™ì€ ì¢Œí‘œê³„!)
            yolo_success = False
            if detection_result.success and detection_result.detection_count > 0:
                self.logger.info("\nğŸ”— ê±´ë¬¼ ë§¤ì¹­ ì¤‘ (ê°™ì€ ì¢Œí‘œê³„)...")
                matches = self.building_matcher.match_all_detections(
                    detection_result,
                    rooftop_positions  # ê°™ì€ ì¢Œí‘œê³„!
                )
                
                result['matches'] = matches
                yolo_success = len(matches) > 0
                
                self.logger.info(f"âœ… {len(matches)}ê°œ ê°ì²´ ë§¤ì¹­ ì™„ë£Œ")
                
                # ë§¤ì¹­ ê²°ê³¼ ì¶œë ¥
                if matches:
                    self.logger.info("\n" + "="*80)
                    self.logger.info("ğŸ“Š YOLO ë§¤ì¹­ ê²°ê³¼:")
                    self.logger.info("="*80)
                    for i, match in enumerate(matches, 1):
                        self.logger.info(f"\n[{i}] ê±´ë¬¼ {match['building_id']}")
                        self.logger.info(f"    - í´ë˜ìŠ¤: {match['detection'].class_name}")
                        self.logger.info(f"    - ì‹ ë¢°ë„: {match['detection'].confidence:.3f}")
                        self.logger.info(f"    - ê±°ë¦¬: {match['distance']:.2f}px")
                        self.logger.info(f"    - íƒì§€ ì¤‘ì‹¬: ({match['center'][0]:.1f}, {match['center'][1]:.1f})")
                        self.logger.info(f"    - ì˜¥ìƒ ì¢Œí‘œ: ({match['rooftop_position'][0]:.1f}, {match['rooftop_position'][1]:.1f})")
                    self.logger.info("="*80)
            else:
                self.logger.warning("âš ï¸ YOLO íƒì§€ ì‹¤íŒ¨ ë˜ëŠ” íƒì§€ëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # 9. ë°±ì—…: ROI ë¶„ì„ (YOLO ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ)
            if not yolo_success and use_backup_roi and roi_paths:
                self.logger.info("\nğŸ” ë°±ì—… ROI ë¶„ì„ ì‹œì‘...")
                
                roi_results = {}
                for building_id, roi_path in roi_paths.items():
                    self.logger.info(f"ê±´ë¬¼ {building_id} ROI ë¶„ì„ ì¤‘...")
                    pred_idx, pred_class, confidence = self.roi_classifier.predict_image(roi_path)
                    
                    if pred_class:
                        roi_results[building_id] = {
                            'class': pred_class,
                            'confidence': confidence,
                            'roi_path': roi_path
                        }
                        self.logger.info(f"ê±´ë¬¼ {building_id}: {pred_class} ({confidence:.2f}%)")
                    else:
                        self.logger.warning(f"ê±´ë¬¼ {building_id} ë¶„ì„ ì‹¤íŒ¨")
                
                result['roi_results'] = roi_results
                
                # OK/NG ê°œìˆ˜ ê³„ì‚°
                ok_count = sum(1 for r in roi_results.values() if r['class'] == 'OK')
                ng_count = sum(1 for r in roi_results.values() if r['class'] == 'NG')
                
                self.logger.info(f"âœ… ROI ë¶„ì„ ê²°ê³¼: OK={ok_count}, NG={ng_count}")
                
                # ROI ë¶„ì„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬
                result['success'] = len(roi_results) > 0
            else:
                # YOLO ë§¤ì¹­ ê²°ê³¼ë¡œ ì„±ê³µ ì—¬ë¶€ ê²°ì •
                result['success'] = yolo_success
            
            # 10. ì‹œê°í™”
            if visualize:
                self.logger.info("\nğŸ¨ ì‹œê°í™” ì¤‘...")
                vis_image = self._visualize_results(
                    transformed_image,
                    result,
                    transformation_matrix,
                    original_image.shape
                )
                
                if save_results:
                    output_path = Path(image_path).parent / f"{Path(image_path).stem}_result.jpg"
                    cv2.imwrite(str(output_path), vis_image)
                    self.logger.info(f"ğŸ’¾ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥: {output_path}")
            
        except Exception as e:
            result['error_message'] = f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            self.logger.error(result['error_message'])
            import traceback
            traceback.print_exc()
        
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if temp_path is not None and temp_path.exists():
                try:
                    temp_path.unlink()
                    self.logger.info(f"ğŸ—‘ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œ: {temp_path}")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
        
        self.logger.info(f"\n{'='*80}")
        self.logger.info(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {'ì„±ê³µ' if result['success'] else 'ì‹¤íŒ¨'}")
        self.logger.info(f"{'='*80}\n")
        
        return result
    
    def _visualize_results(
        self,
        transformed_image: np.ndarray,
        result: Dict,
        transformation_matrix: np.ndarray,
        original_shape: Tuple
    ) -> np.ndarray:
        """ê²°ê³¼ ì‹œê°í™”"""
        vis_image = transformed_image.copy()
        
        # ë“œë¡  ìœ„ì¹˜ ê³„ì‚° (ë³€í™˜ëœ ì´ë¯¸ì§€ì—ì„œ)
        orig_height, orig_width = original_shape[:2]
        drone_point = np.array([[orig_width/2, orig_height/2]], dtype=np.float32).reshape(-1, 1, 2)
        drone_transformed = cv2.perspectiveTransform(drone_point, transformation_matrix)
        drone_x, drone_y = drone_transformed[0][0]
        
        # ë“œë¡  ìœ„ì¹˜ í‘œì‹œ
        cv2.drawMarker(vis_image, (int(drone_x), int(drone_y)),
                      (0, 255, 0), cv2.MARKER_CROSS, 50, 3)
        cv2.putText(vis_image, "DRONE", (int(drone_x) + 20, int(drone_y) - 20),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        # ê±´ë¬¼ ì˜¥ìƒ í‘œì‹œ (ë¹¨ê°„ìƒ‰ ì›)
        for building_id, roof_pos in result['rooftop_positions'].items():
            roof_pos_int = (int(roof_pos[0]), int(roof_pos[1]))
            
            # ê±´ë¬¼ ìƒíƒœ ìƒ‰ìƒ ê²°ì • (ROI ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°)
            color = (0, 0, 255)  # ê¸°ë³¸ ë¹¨ê°„ìƒ‰
            label_text = f"B{building_id}"
            
            if building_id in result.get('roi_results', {}):
                roi_result = result['roi_results'][building_id]
                if roi_result['class'] == 'OK':
                    color = (0, 255, 0)  # OKëŠ” ì´ˆë¡ìƒ‰
                    label_text = f"B{building_id}: OK ({roi_result['confidence']:.1f}%)"
                else:
                    color = (0, 0, 255)  # NGëŠ” ë¹¨ê°„ìƒ‰
                    label_text = f"B{building_id}: NG ({roi_result['confidence']:.1f}%)"
            
            cv2.circle(vis_image, roof_pos_int, 10, color, -1)
            cv2.putText(vis_image, label_text,
                       (roof_pos_int[0] + 15, roof_pos_int[1]),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
        
        # YOLO ë§¤ì¹­ëœ ê°ì²´ í‘œì‹œ
        for match in result.get('matches', []):
            center = match['center']
            center_int = (int(center[0]), int(center[1]))
            bbox = match['bbox']
            
            # ë°”ìš´ë”© ë°•ìŠ¤ (ë…¸ë€ìƒ‰)
            cv2.rectangle(vis_image, 
                         (int(bbox[0]), int(bbox[1])), 
                         (int(bbox[2]), int(bbox[3])),
                         (0, 255, 255), 3)  # BGR: ë…¸ë€ìƒ‰
            
            # ì¤‘ì‹¬ì  (ë…¸ë€ìƒ‰ ì›)
            cv2.circle(vis_image, center_int, 8, (0, 255, 255), -1)
            
            # ê±´ë¬¼ ì˜¥ìƒê³¼ ì—°ê²°ì„  (ì´ˆë¡ìƒ‰)
            roof_pos = match['rooftop_position']
            roof_pos_int = (int(roof_pos[0]), int(roof_pos[1]))
            cv2.line(vis_image, center_int, roof_pos_int, (0, 255, 0), 2)
            
            # ë¼ë²¨
            label = f"B{match['building_id']}: {match['detection'].class_name} ({match['detection'].confidence:.2f})"
            cv2.putText(vis_image, label,
                       (int(bbox[0]), int(bbox[1]) - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
            
            # ê±°ë¦¬ ì •ë³´
            distance_text = f"{match['distance']:.1f}px"
            cv2.putText(vis_image, distance_text,
                       (center_int[0] - 30, center_int[1] + 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
        
        # ì •ë³´ íŒ¨ë„
        info_y = 50
        cv2.putText(vis_image, f"Altitude: {result['drone_altitude_m']:.2f}m",
                   (50, info_y), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)
        
        info_y += 50
        if result.get('detection_result'):
            cv2.putText(vis_image, f"YOLO: {result['detection_result'].detection_count} detections",
                       (50, info_y), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)
        
        info_y += 50
        matches_count = len(result.get('matches', []))
        cv2.putText(vis_image, f"Matches: {matches_count}",
                   (50, info_y), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)
        
        info_y += 50
        roi_results = result.get('roi_results', {})
        if roi_results:
            ok_count = sum(1 for r in roi_results.values() if r['class'] == 'OK')
            ng_count = sum(1 for r in roi_results.values() if r['class'] == 'NG')
            cv2.putText(vis_image, f"ROI: OK={ok_count}, NG={ng_count}",
                       (50, info_y), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)
        
        return vis_image
    
    def process_batch(
        self,
        folder_path: str,
        output_csv: str = 'drone_analysis_results.csv',
        visualize: bool = True,
        save_results: bool = True,
        use_backup_roi: bool = True
    ) -> List[Dict]:
        """
        í´ë” ë‚´ ì´ë¯¸ì§€ ë°°ì¹˜ ì²˜ë¦¬
        
        Args:
            folder_path: ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
            output_csv: ê²°ê³¼ CSV íŒŒì¼ ê²½ë¡œ
            visualize: ì‹œê°í™” ì—¬ë¶€
            save_results: ê²°ê³¼ ì €ì¥ ì—¬ë¶€
            use_backup_roi: YOLO ì‹¤íŒ¨ ì‹œ ë°±ì—… ROI ë¶„ì„ ì‚¬ìš© ì—¬ë¶€
            
        Returns:
            list: ì²˜ë¦¬ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        self.logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {folder_path}")
        
        # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
        image_files = []
        for file_ext in ['.jpg', '.jpeg', '.png', '.bmp']:
            image_files.extend(list(Path(folder_path).glob(f"*{file_ext}")))
            image_files.extend(list(Path(folder_path).glob(f"*{file_ext.upper()}")))
        
        # _result.jpg, _transformed_temp.jpg ì œì™¸
        image_files = [f for f in image_files 
                      if not f.stem.endswith('_result') 
                      and not f.stem.endswith('_transformed_temp')]
        
        self.logger.info(f"ì´ {len(image_files)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘...")
        
        # ê²°ê³¼ ì €ì¥
        results = []
        
        # ê° ì´ë¯¸ì§€ ì²˜ë¦¬
        for idx, image_path in enumerate(image_files, 1):
            self.logger.info(f"\n{'='*60}")
            self.logger.info(f"[{idx}/{len(image_files)}] ì²˜ë¦¬ ì¤‘: {image_path.name}")
            self.logger.info(f"{'='*60}")
            
            try:
                # ì´ë¯¸ì§€ ì²˜ë¦¬
                result = self.process_image(
                    str(image_path),
                    visualize=visualize,
                    save_results=save_results,
                    use_backup_roi=use_backup_roi
                )
                results.append(result)
                
                # ì§„í–‰ ìƒí™© í‘œì‹œ
                if result['success']:
                    if result.get('matches'):
                        self.logger.info(f"âœ… YOLO ë§¤ì¹­ ì„±ê³µ: {len(result['matches'])}ê°œ ë§¤ì¹­")
                    elif result.get('roi_results'):
                        ok_count = sum(1 for r in result['roi_results'].values() if r['class'] == 'OK')
                        ng_count = sum(1 for r in result['roi_results'].values() if r['class'] == 'NG')
                        self.logger.info(f"âœ… ROI ë¶„ì„ ì„±ê³µ: OK={ok_count}, NG={ng_count}")
                else:
                    self.logger.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('error_message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
                    
            except Exception as e:
                self.logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                traceback.print_exc()
                results.append({
                    'success': False,
                    'image_path': str(image_path),
                    'error_message': str(e)
                })
        
        # ê²°ê³¼ ìš”ì•½
        success_count = sum(1 for r in results if r['success'])
        yolo_success = sum(1 for r in results if r.get('matches'))
        roi_success = sum(1 for r in results if not r.get('matches') and r.get('roi_results'))
        
        self.logger.info(f"\n{'='*80}")
        self.logger.info(f"ğŸ“Š ë°°ì¹˜ ì²˜ë¦¬ ìš”ì•½")
        self.logger.info(f"{'='*80}")
        self.logger.info(f"ì´ ì´ë¯¸ì§€: {len(results)}ê°œ")
        self.logger.info(f"ì„±ê³µ: {success_count}ê°œ ({success_count/len(results)*100:.1f}%)")
        self.logger.info(f"- YOLO ì„±ê³µ: {yolo_success}ê°œ")
        self.logger.info(f"- ROI ë°±ì—… ì„±ê³µ: {roi_success}ê°œ")
        self.logger.info(f"ì‹¤íŒ¨: {len(results) - success_count}ê°œ")
        self.logger.info(f"{'='*80}")
        
        # CSV ì €ì¥
        self.save_results_to_csv(results, output_csv)
        
        return results
    
    def save_results_to_csv(self, results, output_csv):
        """ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
        with open(output_csv, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            
            # í—¤ë” ì‘ì„±
            header = ['ì´ë¯¸ì§€ ê²½ë¡œ', 'ì²˜ë¦¬ ì„±ê³µ', 'Hë§ˆì»¤ ì¸ì‹', 'ë“œë¡  ê³ ë„(m)', 'YOLO ë§¤ì¹­ ìˆ˜']
            for i in range(1, 10):  # ê±´ë¬¼ 1~9
                header.extend([f'ê±´ë¬¼{i} YOLOí´ë˜ìŠ¤', f'ê±´ë¬¼{i} YOLOì‹ ë¢°ë„', f'ê±´ë¬¼{i} ROIí´ë˜ìŠ¤', f'ê±´ë¬¼{i} ROIì‹ ë¢°ë„'])
            writer.writerow(header)
            
            # ë°ì´í„° ì‘ì„±
            for result in results:
                # ê¸°ë³¸ ì •ë³´
                row = [
                    result['image_path'],
                    result['success'],
                    result.get('h_marker_detected', False),
                    f"{result.get('drone_altitude_m', 0):.2f}" if result.get('drone_altitude_m') else 'N/A',
                    len(result.get('matches', []))
                ]
                
                # ê° ê±´ë¬¼ë³„ ê²°ê³¼ ì¶”ê°€
                for building_id in range(1, 10):
                    # YOLO ë§¤ì¹­ ê²°ê³¼
                    yolo_match = next((m for m in result.get('matches', []) if m['building_id'] == building_id), None)
                    if yolo_match:
                        row.extend([
                            yolo_match['detection'].class_name,
                            f"{yolo_match['detection'].confidence:.2f}"
                        ])
                    else:
                        row.extend(['N/A', 'N/A'])
                    
                    # ROI ë¶„ì„ ê²°ê³¼
                    roi_result = result.get('roi_results', {}).get(building_id)
                    if roi_result:
                        row.extend([
                            roi_result['class'],
                            f"{roi_result['confidence']:.2f}"
                        ])
                    else:
                        row.extend(['N/A', 'N/A'])
                
                writer.writerow(row)
        
        self.logger.info(f"ê²°ê³¼ê°€ {output_csv}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ========================================
# ğŸ¯ ë©”ì¸ í•¨ìˆ˜
# ========================================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    logger = logging.getLogger('main')
    logger.info("ğŸš ë“œë¡  í†µí•© ì‹œìŠ¤í…œ ì‹œì‘")
    
    # ì„¤ì • ì¶œë ¥
    logger.info(f"âš™ï¸ ì„¤ì •:")
    logger.info(f"  - ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {ORIGINAL_IMAGE_WIDTH}x{ORIGINAL_IMAGE_HEIGHT}")
    logger.info(f"  - YOLO ì…ë ¥ í¬ê¸°: {YOLO_INPUT_SIZE}x{YOLO_INPUT_SIZE}")
    logger.info(f"  - ë§¤ì¹­ ê±°ë¦¬ ì„ê³„ê°’: {MATCHING_DISTANCE_THRESHOLD}px")
    logger.info(f"  - ROI í¬ê¸°: {CROP_SIZE_PIXELS}x{CROP_SIZE_PIXELS}px")
    logger.info(f"  - ROI ì €ì¥ ê²½ë¡œ: {OUTPUT_BASE_DIR}")
    
    try:
        # 1. YOLO ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
        yolo_classifier = YoloClassifier(
            model_path='runs/detect/drone_yolov8s/weights/best.pt',
            device=0,
            confidence_threshold=0.5,
            required_count=2,
            save_outputs=False
        )
        
        # 2. í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        drone_system = DroneIntegratedSystem(
            yolo_classifier=yolo_classifier,
            roi_classifier_path='best_drone_model.pth',
            h_marker_template_path='src/drone/h_template.png',
            buildings_info=BUILDINGS_INFO,
            distance_threshold=MATCHING_DISTANCE_THRESHOLD
        )
        
        # 3. ëª…ë ¹ì¤„ ì¸ìˆ˜ í™•ì¸
        if len(sys.argv) > 1:
            # ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬
            if os.path.isfile(sys.argv[1]):
                image_path = sys.argv[1]
                logger.info(f"ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬: {image_path}")
                
                result = drone_system.process_image(
                    image_path,
                    visualize=True,
                    save_results=True,
                    use_backup_roi=True
                )
                
                # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
                if result['success']:
                    if result.get('matches'):
                        logger.info(f"âœ… YOLO ë§¤ì¹­ ì„±ê³µ: {len(result['matches'])}ê°œ ë§¤ì¹­")
                    elif result.get('roi_results'):
                        ok_count = sum(1 for r in result['roi_results'].values() if r['class'] == 'OK')
                        ng_count = sum(1 for r in result['roi_results'].values() if r['class'] == 'NG')
                        logger.info(f"âœ… ROI ë¶„ì„ ì„±ê³µ: OK={ok_count}, NG={ng_count}")
                else:
                    logger.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('error_message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            
            # í´ë” ì²˜ë¦¬
            elif os.path.isdir(sys.argv[1]):
                folder_path = sys.argv[1]
                output_csv = sys.argv[2] if len(sys.argv) > 2 else 'drone_analysis_results.csv'
                
                logger.info(f"í´ë” ì²˜ë¦¬: {folder_path}")
                drone_system.process_batch(
                    folder_path,
                    output_csv=output_csv,
                    visualize=True,
                    save_results=True,
                    use_backup_roi=True
                )
            
            else:
                logger.error(f"ì˜¤ë¥˜: íŒŒì¼ ë˜ëŠ” í´ë”ê°€ ì•„ë‹™ë‹ˆë‹¤: {sys.argv[1]}")
        
        # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ í´ë” ì²˜ë¦¬
        else:
            test_dir = 'src/drone/temp'
            logger.info(f"ê¸°ë³¸ í…ŒìŠ¤íŠ¸ í´ë” ì²˜ë¦¬: {test_dir}")
            
            if os.path.exists(test_dir):
                drone_system.process_batch(
                    test_dir,
                    output_csv='drone_analysis_results.csv',
                    visualize=True,
                    save_results=True,
                    use_backup_roi=True
                )
            else:
                logger.error(f"í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_dir}")
    
    except Exception as e:
        logger.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    
    logger.info("âœ… ë“œë¡  í†µí•© ì‹œìŠ¤í…œ ì¢…ë£Œ")

if __name__ == '__main__':
    main()

"""
ë“œë¡  íƒì§€ ë° ë¶„ì„ ë¶„ë¥˜ê¸°
"""

import os
import sys
import json
import cv2
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass, asdict
import logging

# YOLO ì„í¬íŠ¸
from ultralytics import YOLO
import torch

# ì„¤ì • íŒŒì¼ ì„í¬íŠ¸
try:
    from config import *
except ImportError:
    print("âš ï¸ config.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    # ê¸°ë³¸ê°’ ì„¤ì •
    REQUIRED_DETECTION_COUNT = 2
    MIN_DETECTION_COUNT = 2
    MAX_DETECTION_COUNT = 2
    CONFIDENCE_THRESHOLD = 0.5
    IOU_THRESHOLD = 0.45
    MODEL_PATH = 'runs/detect/drone_yolov8s/weights/best.pt'
    DEVICE = 0
    IMG_SIZE = 640
    GRID_ROWS = 3
    GRID_COLS = 3
    BBOX_COLOR = (0, 255, 0)
    BBOX_THICKNESS = 2
    OUTPUT_DIR = Path('outputs/detections')
    LOG_DIR = Path('outputs/logs')
    SAVE_IMAGES = True
    SAVE_JSON = True
    CLASS_NAMES = ['drone']
    DEBUG = True


# ========================================
# ğŸ“¦ ë°ì´í„° í´ë˜ìŠ¤
# ========================================

@dataclass
class BoundingBox:
    """ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´"""
    x1: float  # ì¢Œìƒë‹¨ x
    y1: float  # ì¢Œìƒë‹¨ y
    x2: float  # ìš°í•˜ë‹¨ x
    y2: float  # ìš°í•˜ë‹¨ y
    width: float  # ë„ˆë¹„
    height: float  # ë†’ì´
    center_x: float  # ì¤‘ì‹¬ x
    center_y: float  # ì¤‘ì‹¬ y
    area: float  # ë©´ì 
    
    def to_dict(self) -> Dict:
        return asdict(self)


@dataclass
class Detection:
    """ë‹¨ì¼ íƒì§€ ê²°ê³¼"""
    class_id: int
    class_name: str
    confidence: float
    bbox: BoundingBox
    position_grid: Tuple[int, int]  # (row, col)
    position_label: str  # "ì¤‘ì•™", "ì¢Œìƒë‹¨" ë“±
    position_label_en: str  # "center", "top-left" ë“±
    
    def to_dict(self) -> Dict:
        return {
            'class_id': self.class_id,
            'class_name': self.class_name,
            'confidence': float(self.confidence),
            'bbox': self.bbox.to_dict(),
            'position_grid': self.position_grid,
            'position_label': self.position_label,
            'position_label_en': self.position_label_en
        }


@dataclass
class DetectionResult:
    """ì „ì²´ íƒì§€ ê²°ê³¼"""
    success: bool  # íƒì§€ ì„±ê³µ ì—¬ë¶€
    message: str  # ìƒíƒœ ë©”ì‹œì§€
    detection_count: int  # íƒì§€ëœ ê°ì²´ ìˆ˜
    required_count: int  # ìš”êµ¬ë˜ëŠ” íƒì§€ ìˆ˜
    detections: List[Detection]  # íƒì§€ ëª©ë¡
    image_shape: Tuple[int, int, int]  # (height, width, channels)
    timestamp: str  # íƒì§€ ì‹œê°„
    inference_time: float  # ì¶”ë¡  ì‹œê°„ (ms)
    
    def to_dict(self) -> Dict:
        return {
            'success': self.success,
            'message': self.message,
            'detection_count': self.detection_count,
            'required_count': self.required_count,
            'detections': [d.to_dict() for d in self.detections],
            'image_shape': self.image_shape,
            'timestamp': self.timestamp,
            'inference_time': float(self.inference_time)
        }
    
    def get_positions_array(self) -> np.ndarray:
        """
        íƒì§€ëœ ê°ì²´ë“¤ì˜ ì¤‘ì‹¬ ì¢Œí‘œë¥¼ numpy arrayë¡œ ë°˜í™˜
        
        Returns:
            np.ndarray: shape (N, 2), [[x1, y1], [x2, y2], ...]
        """
        if not self.detections:
            return np.array([]).reshape(0, 2)
        
        positions = np.array([
            [det.bbox.center_x, det.bbox.center_y]
            for det in self.detections
        ])
        return positions
    
    def get_bboxes_array(self) -> np.ndarray:
        """
        íƒì§€ëœ ê°ì²´ë“¤ì˜ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ numpy arrayë¡œ ë°˜í™˜
        
        Returns:
            np.ndarray: shape (N, 4), [[x1, y1, x2, y2], ...]
        """
        if not self.detections:
            return np.array([]).reshape(0, 4)
        
        bboxes = np.array([
            [det.bbox.x1, det.bbox.y1, det.bbox.x2, det.bbox.y2]
            for det in self.detections
        ])
        return bboxes


# ========================================
# ğŸ¤– ë“œë¡  ë¶„ë¥˜ê¸° í´ë˜ìŠ¤
# ========================================

class DroneClassifier:
    """
    ë“œë¡  íƒì§€ ë° ë¶„ì„ ë¶„ë¥˜ê¸°
    """
    
    def __init__(
        self,
        model_path: str = MODEL_PATH,
        device: int = DEVICE,
        confidence_threshold: float = CONFIDENCE_THRESHOLD,
        iou_threshold: float = IOU_THRESHOLD,
        required_count: int = REQUIRED_DETECTION_COUNT,
        img_size: int = IMG_SIZE,
        save_outputs: bool = True
    ):
        """
        ì´ˆê¸°í™”
        
        Args:
            model_path: ëª¨ë¸ ê°€ì¤‘ì¹˜ ê²½ë¡œ
            device: ë””ë°”ì´ìŠ¤ (0: GPU, 'cpu': CPU)
            confidence_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
            iou_threshold: NMS IoU ì„ê³„ê°’
            required_count: í•„ìˆ˜ íƒì§€ ê°œìˆ˜
            img_size: ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°
            save_outputs: ê²°ê³¼ ì €ì¥ ì—¬ë¶€
        """
        
        # ë¡œê¹… ì„¤ì •
        self._setup_logging()
        
        # ì„¤ì • ì €ì¥
        self.model_path = model_path
        self.device = device
        self.confidence_threshold = confidence_threshold
        self.iou_threshold = iou_threshold
        self.required_count = required_count
        self.img_size = img_size
        self.save_outputs = save_outputs
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        if self.save_outputs:
            OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
            LOG_DIR.mkdir(parents=True, exist_ok=True)
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = self._load_model()
        
        self.logger.info("âœ… DroneClassifier ì´ˆê¸°í™” ì™„ë£Œ")
        self.logger.info(f"   - ëª¨ë¸: {model_path}")
        self.logger.info(f"   - ë””ë°”ì´ìŠ¤: {device}")
        self.logger.info(f"   - ì‹ ë¢°ë„ ì„ê³„ê°’: {confidence_threshold}")
        self.logger.info(f"   - í•„ìˆ˜ íƒì§€ ê°œìˆ˜: {required_count}")
    
    def _setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        self.logger = logging.getLogger('DroneClassifier')
        self.logger.setLevel(logging.DEBUG if DEBUG else logging.INFO)
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬
        if not self.logger.handlers:
            console_handler = logging.StreamHandler(sys.stdout)
            console_handler.setLevel(logging.DEBUG if DEBUG else logging.INFO)
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            console_handler.setFormatter(formatter)
            self.logger.addHandler(console_handler)
    
    def _load_model(self) -> YOLO:
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            if not Path(self.model_path).exists():
                self.logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
                self.logger.info("ê¸°ë³¸ ëª¨ë¸(yolov8s.pt)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                self.model_path = 'yolov8s.pt'
            
            model = YOLO(self.model_path)
            
            # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            if torch.cuda.is_available() and self.device != 'cpu':
                self.logger.info(f"ğŸš€ GPU ì‚¬ìš©: {torch.cuda.get_device_name(0)}")
            else:
                self.logger.info("ğŸ’» CPU ì‚¬ìš©")
            
            return model
        
        except Exception as e:
            self.logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def _calculate_position(
        self,
        center_x: float,
        center_y: float,
        img_width: int,
        img_height: int
    ) -> Tuple[Tuple[int, int], str, str]:
        """
        ê°ì²´ì˜ ì¤‘ì‹¬ ì¢Œí‘œë¡œë¶€í„° ê·¸ë¦¬ë“œ ìœ„ì¹˜ ê³„ì‚°
        
        Args:
            center_x: ì¤‘ì‹¬ x ì¢Œí‘œ
            center_y: ì¤‘ì‹¬ y ì¢Œí‘œ
            img_width: ì´ë¯¸ì§€ ë„ˆë¹„
            img_height: ì´ë¯¸ì§€ ë†’ì´
        
        Returns:
            ((row, col), position_label, position_label_en)
        """
        
        # ê·¸ë¦¬ë“œ ì…€ í¬ê¸°
        cell_width = img_width / GRID_COLS
        cell_height = img_height / GRID_ROWS
        
        # ê·¸ë¦¬ë“œ ì¸ë±ìŠ¤ ê³„ì‚°
        col = min(int(center_x / cell_width), GRID_COLS - 1)
        row = min(int(center_y / cell_height), GRID_ROWS - 1)
        
        # ìœ„ì¹˜ ë¼ë²¨
        position_label = POSITION_LABELS[row][col]
        position_label_en = POSITION_LABELS_EN[row][col]
        
        return (row, col), position_label, position_label_en
    
    def detect(
        self,
        image: np.ndarray,
        visualize: bool = True
    ) -> DetectionResult:
        """
        ì´ë¯¸ì§€ì—ì„œ ë“œë¡  íƒì§€
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (BGR)
            visualize: ì‹œê°í™” ì—¬ë¶€
        
        Returns:
            DetectionResult: íƒì§€ ê²°ê³¼
        """
        
        start_time = cv2.getTickCount()
        
        # ì´ë¯¸ì§€ ê²€ì¦
        if image is None or image.size == 0:
            self.logger.error("âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ì…ë‹ˆë‹¤.")
            return DetectionResult(
                success=False,
                message="ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€",
                detection_count=0,
                required_count=self.required_count,
                detections=[],
                image_shape=(0, 0, 0),
                timestamp=datetime.now().isoformat(),
                inference_time=0.0
            )
        
        img_height, img_width = image.shape[:2]
        
        # YOLO ì¶”ë¡ 
        try:
            results = self.model.predict(
                image,
                imgsz=self.img_size,
                conf=self.confidence_threshold,
                iou=self.iou_threshold,
                device=self.device,
                verbose=False
            )
        except Exception as e:
            self.logger.error(f"âŒ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return DetectionResult(
                success=False,
                message=f"ì¶”ë¡  ì‹¤íŒ¨: {e}",
                detection_count=0,
                required_count=self.required_count,
                detections=[],
                image_shape=image.shape,
                timestamp=datetime.now().isoformat(),
                inference_time=0.0
            )
        
        # ì¶”ë¡  ì‹œê°„ ê³„ì‚°
        inference_time = (cv2.getTickCount() - start_time) / cv2.getTickFrequency() * 1000
        
        # ê²°ê³¼ íŒŒì‹±
        detections = []
        
        if len(results) > 0 and results[0].boxes is not None:
            boxes = results[0].boxes
            
            for i in range(len(boxes)):
                # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ
                x1, y1, x2, y2 = boxes.xyxy[i].cpu().numpy()
                
                # ì‹ ë¢°ë„
                confidence = float(boxes.conf[i].cpu().numpy())
                
                # í´ë˜ìŠ¤ ID
                class_id = int(boxes.cls[i].cpu().numpy())
                class_name = CLASS_NAMES[class_id] if class_id < len(CLASS_NAMES) else f"class_{class_id}"
                
                # ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ê³„ì‚°
                width = x2 - x1
                height = y2 - y1
                center_x = (x1 + x2) / 2
                center_y = (y1 + y2) / 2
                area = width * height
                
                bbox = BoundingBox(
                    x1=float(x1), y1=float(y1),
                    x2=float(x2), y2=float(y2),
                    width=float(width), height=float(height),
                    center_x=float(center_x), center_y=float(center_y),
                    area=float(area)
                )
                
                # ìœ„ì¹˜ ê³„ì‚°
                position_grid, position_label, position_label_en = self._calculate_position(
                    center_x, center_y, img_width, img_height
                )
                
                # Detection ê°ì²´ ìƒì„±
                detection = Detection(
                    class_id=class_id,
                    class_name=class_name,
                    confidence=confidence,
                    bbox=bbox,
                    position_grid=position_grid,
                    position_label=position_label,
                    position_label_en=position_label_en
                )
                
                detections.append(detection)
        
        # íƒì§€ ê°œìˆ˜ í™•ì¸
        detection_count = len(detections)
        
        # ì„±ê³µ ì—¬ë¶€ íŒë‹¨
        if detection_count == self.required_count:
            success = True
            message = f"âœ… íƒì§€ ì„±ê³µ: {detection_count}ê°œ íƒì§€ë¨"
        elif detection_count == 0:
            success = False
            message = f"âŒ ê²€ì¶œ ì•ˆë¨ (ìš”êµ¬: {self.required_count}ê°œ)"
        elif detection_count < self.required_count:
            success = False
            message = f"âš ï¸ íƒì§€ ë¶€ì¡±: {detection_count}ê°œ íƒì§€ë¨ (ìš”êµ¬: {self.required_count}ê°œ)"
        else:
            success = False
            message = f"âš ï¸ ê³¼ë‹¤ íƒì§€: {detection_count}ê°œ íƒì§€ë¨ (ìš”êµ¬: {self.required_count}ê°œ)"
        
        # ê²°ê³¼ ìƒì„±
        result = DetectionResult(
            success=success,
            message=message,
            detection_count=detection_count,
            required_count=self.required_count,
            detections=detections,
            image_shape=image.shape,
            timestamp=datetime.now().isoformat(),
            inference_time=inference_time
        )
        
        # ë¡œê¹…
        self.logger.info(f"{message} (ì¶”ë¡  ì‹œê°„: {inference_time:.1f}ms)")
        
        # ì‹œê°í™”
        if visualize and detection_count > 0:
            self._visualize(image, result)
        
        return result
    
    
     #ë””ë²„ê¹…ìš© detect, ì‚­ì œ ê°€ëŠ¥.
 
    '''
    def detect(
        self,
        image: np.ndarray,
        visualize: bool = True
    ) -> DetectionResult:
        """
        ì´ë¯¸ì§€ì—ì„œ ë“œë¡  íƒì§€
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (BGR)
            visualize: ì‹œê°í™” ì—¬ë¶€
        
        Returns:
            DetectionResult: íƒì§€ ê²°ê³¼
        """
        
        start_time = cv2.getTickCount()
        
        # ì´ë¯¸ì§€ ê²€ì¦
        if image is None or image.size == 0:
            self.logger.error("âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ì…ë‹ˆë‹¤.")
            return DetectionResult(
                success=False,
                message="ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€",
                detection_count=0,
                required_count=self.required_count,
                detections=[],
                image_shape=(0, 0, 0),
                timestamp=datetime.now().isoformat(),
                inference_time=0.0
            )
        
        # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°
        img_height, img_width = image.shape[:2]
        self.logger.info(f"ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {img_width}x{img_height}")
        
        # YOLO ì¶”ë¡ 
        try:
            results = self.model.predict(
                image,
                imgsz=self.img_size,
                conf=self.confidence_threshold,
                iou=self.iou_threshold,
                device=self.device,
                verbose=False
            )
        except Exception as e:
            self.logger.error(f"âŒ ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return DetectionResult(
                success=False,
                message=f"ì¶”ë¡  ì‹¤íŒ¨: {e}",
                detection_count=0,
                required_count=self.required_count,
                detections=[],
                image_shape=image.shape,
                timestamp=datetime.now().isoformat(),
                inference_time=0.0
            )
        
        # ì¶”ë¡  ì‹œê°„ ê³„ì‚°
        inference_time = (cv2.getTickCount() - start_time) / cv2.getTickFrequency() * 1000
        
        # ğŸ” ë””ë²„ê·¸: YOLOê°€ ì‚¬ìš©í•œ ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
        if len(results) > 0:
            result = results[0]
            if hasattr(result, 'orig_shape'):
                self.logger.info(f"YOLO orig_shape: {result.orig_shape}")
            if hasattr(result, 'shape'):
                self.logger.info(f"YOLO processed shape: {result.shape}")
        
        # ê²°ê³¼ íŒŒì‹±
        detections = []
        
        if len(results) > 0 and results[0].boxes is not None:
            boxes = results[0].boxes
            
            for i in range(len(boxes)):
                # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ (xyxy í˜•ì‹)
                x1, y1, x2, y2 = boxes.xyxy[i].cpu().numpy()
                
                # ğŸ” ë””ë²„ê·¸: ì²« ë²ˆì§¸ íƒì§€ ê°ì²´ì˜ ì¢Œí‘œ ë²”ìœ„ í™•ì¸
                if i == 0:
                    self.logger.info(f"ì²« ë²ˆì§¸ íƒì§€ ì¢Œí‘œ: ({x1:.1f}, {y1:.1f}) â†’ ({x2:.1f}, {y2:.1f})")
                    self.logger.info(f"ì¢Œí‘œ ë²”ìœ„ í™•ì¸:")
                    self.logger.info(f"  - x ë²”ìœ„: 0 ~ {img_width} (ì¢Œí‘œ: {x1:.1f} ~ {x2:.1f})")
                    self.logger.info(f"  - y ë²”ìœ„: 0 ~ {img_height} (ì¢Œí‘œ: {y1:.1f} ~ {y2:.1f})")
                    
                    # ì¢Œí‘œê°€ ì›ë³¸ í¬ê¸° ê¸°ì¤€ì¸ì§€ 640 ê¸°ì¤€ì¸ì§€ íŒë‹¨
                    if x2 <= 640 and y2 <= 640:
                        self.logger.warning("âš ï¸ ì¢Œí‘œê°€ 640x640 ê¸°ì¤€ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤!")
                    elif x2 <= img_width and y2 <= img_height:
                        self.logger.info("âœ… ì¢Œí‘œê°€ ì›ë³¸ í¬ê¸° ê¸°ì¤€ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.")
                
                # ì‹ ë¢°ë„
                confidence = float(boxes.conf[i].cpu().numpy())
                
                # í´ë˜ìŠ¤ ID
                class_id = int(boxes.cls[i].cpu().numpy())
                class_name = CLASS_NAMES[class_id] if class_id < len(CLASS_NAMES) else f"class_{class_id}"
                
                # ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ê³„ì‚°
                width = x2 - x1
                height = y2 - y1
                center_x = (x1 + x2) / 2
                center_y = (y1 + y2) / 2
                area = width * height
                
                bbox = BoundingBox(
                    x1=float(x1), y1=float(y1),
                    x2=float(x2), y2=float(y2),
                    width=float(width), height=float(height),
                    center_x=float(center_x), center_y=float(center_y),
                    area=float(area)
                )
                
                # ìœ„ì¹˜ ê³„ì‚°
                position_grid, position_label, position_label_en = self._calculate_position(
                    center_x, center_y, img_width, img_height
                )
                
                # Detection ê°ì²´ ìƒì„±
                detection = Detection(
                    class_id=class_id,
                    class_name=class_name,
                    confidence=confidence,
                    bbox=bbox,
                    position_grid=position_grid,
                    position_label=position_label,
                    position_label_en=position_label_en
                )
                
                detections.append(detection)
        
        # íƒì§€ ê°œìˆ˜ í™•ì¸
        detection_count = len(detections)
        
        # ì„±ê³µ ì—¬ë¶€ íŒë‹¨
        if detection_count == self.required_count:
            success = True
            message = f"âœ… íƒì§€ ì„±ê³µ: {detection_count}ê°œ íƒì§€ë¨"
        elif detection_count == 0:
            success = False
            message = f"âŒ ê²€ì¶œ ì•ˆë¨ (ìš”êµ¬: {self.required_count}ê°œ)"
        elif detection_count < self.required_count:
            success = False
            message = f"âš ï¸ íƒì§€ ë¶€ì¡±: {detection_count}ê°œ íƒì§€ë¨ (ìš”êµ¬: {self.required_count}ê°œ)"
        else:
            success = False
            message = f"âš ï¸ ê³¼ë‹¤ íƒì§€: {detection_count}ê°œ íƒì§€ë¨ (ìš”êµ¬: {self.required_count}ê°œ)"
        
        # ê²°ê³¼ ìƒì„±
        result = DetectionResult(
            success=success,
            message=message,
            detection_count=detection_count,
            required_count=self.required_count,
            detections=detections,
            image_shape=image.shape,
            timestamp=datetime.now().isoformat(),
            inference_time=inference_time
        )
        
        # ë¡œê¹…
        self.logger.info(f"{message} (ì¶”ë¡  ì‹œê°„: {inference_time:.1f}ms)")
        
        # ì‹œê°í™”
        if visualize and detection_count > 0:
            self._visualize(image, result)
        
        return result
    '''
    def _visualize(self, image: np.ndarray, result: DetectionResult):
        """
        íƒì§€ ê²°ê³¼ ì‹œê°í™”
        
        Args:
            image: ì›ë³¸ ì´ë¯¸ì§€
            result: íƒì§€ ê²°ê³¼
        """
        
        vis_image = image.copy()
        
        for det in result.detections:
            bbox = det.bbox
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            cv2.rectangle(
                vis_image,
                (int(bbox.x1), int(bbox.y1)),
                (int(bbox.x2), int(bbox.y2)),
                BBOX_COLOR,
                BBOX_THICKNESS
            )
            
            # ë¼ë²¨ í…ìŠ¤íŠ¸
            label = f"{det.class_name} {det.confidence:.2f}"
            position_text = f"{det.position_label}"
            
            # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°
            (label_w, label_h), _ = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, FONT_THICKNESS
            )
            
            # í…ìŠ¤íŠ¸ ë°°ê²½
            cv2.rectangle(
                vis_image,
                (int(bbox.x1), int(bbox.y1) - label_h - 10),
                (int(bbox.x1) + label_w, int(bbox.y1)),
                TEXT_BG_COLOR,
                -1
            )
            
            # í…ìŠ¤íŠ¸
            cv2.putText(
                vis_image,
                label,
                (int(bbox.x1), int(bbox.y1) - 5),
                cv2.FONT_HERSHEY_SIMPLEX,
                FONT_SCALE,
                TEXT_COLOR,
                FONT_THICKNESS
            )
            
            # ìœ„ì¹˜ ì •ë³´
            cv2.putText(
                vis_image,
                position_text,
                (int(bbox.center_x) - 30, int(bbox.center_y)),
                cv2.FONT_HERSHEY_SIMPLEX,
                FONT_SCALE,
                (0, 0, 255),
                FONT_THICKNESS
            )
            
            # ì¤‘ì‹¬ì  í‘œì‹œ
            cv2.circle(
                vis_image,
                (int(bbox.center_x), int(bbox.center_y)),
                5,
                (0, 0, 255),
                -1
            )
        
        # ìƒíƒœ ë©”ì‹œì§€
        status_color = (0, 255, 0) if result.success else (0, 0, 255)
        cv2.putText(
            vis_image,
            result.message,
            (10, 30),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.8,
            status_color,
            2
        )
        
        # ê²°ê³¼ ì €ì¥
        if self.save_outputs:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
            output_path = OUTPUT_DIR / f"detection_{timestamp}.jpg"
            cv2.imwrite(str(output_path), vis_image)
            self.logger.info(f"ğŸ’¾ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥: {output_path}")
        
        return vis_image
    
    def detect_from_file(
        self,
        image_path: str,
        visualize: bool = True,
        save_json: bool = True
    ) -> DetectionResult:
        """
        ì´ë¯¸ì§€ íŒŒì¼ì—ì„œ ë“œë¡  íƒì§€
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            visualize: ì‹œê°í™” ì—¬ë¶€
            save_json: JSON ì €ì¥ ì—¬ë¶€
        
        Returns:
            DetectionResult: íƒì§€ ê²°ê³¼
        """
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(image_path)
        
        if image is None:
            self.logger.error(f"âŒ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            return DetectionResult(
                success=False,
                message=f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}",
                detection_count=0,
                required_count=self.required_count,
                detections=[],
                image_shape=(0, 0, 0),
                timestamp=datetime.now().isoformat(),
                inference_time=0.0
            )
        
        self.logger.info(f"ğŸ“· ì´ë¯¸ì§€ ë¡œë“œ: {image_path}")
        
        # íƒì§€ ìˆ˜í–‰
        result = self.detect(image, visualize=visualize)
        
        # JSON ì €ì¥
        if save_json and self.save_outputs:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')
            json_path = OUTPUT_DIR / f"detection_{timestamp}.json"
            
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(result.to_dict(), f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"ğŸ’¾ ê²°ê³¼ JSON ì €ì¥: {json_path}")
        
        return result
    
    def detect_batch(
        self,
        image_paths: List[str],
        visualize: bool = True,
        save_json: bool = True
    ) -> List[DetectionResult]:
        """
        ì—¬ëŸ¬ ì´ë¯¸ì§€ì—ì„œ ë°°ì¹˜ íƒì§€
        
        Args:
            image_paths: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            visualize: ì‹œê°í™” ì—¬ë¶€
            save_json: JSON ì €ì¥ ì—¬ë¶€
        
        Returns:
            List[DetectionResult]: íƒì§€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        
        results = []
        
        self.logger.info(f"ğŸ”„ ë°°ì¹˜ íƒì§€ ì‹œì‘: {len(image_paths)}ê°œ ì´ë¯¸ì§€")
        
        for i, image_path in enumerate(image_paths, 1):
            self.logger.info(f"\n[{i}/{len(image_paths)}] {image_path}")
            result = self.detect_from_file(image_path, visualize, save_json=False)
            results.append(result)
        
        # ì „ì²´ ê²°ê³¼ JSON ì €ì¥
        if save_json and self.save_outputs:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            json_path = OUTPUT_DIR / f"batch_detection_{timestamp}.json"
            
            batch_result = {
                'total_images': len(image_paths),
                'successful_detections': sum(1 for r in results if r.success),
                'results': [r.to_dict() for r in results]
            }
            
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(batch_result, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"\nğŸ’¾ ë°°ì¹˜ ê²°ê³¼ JSON ì €ì¥: {json_path}")
        
        # ìš”ì•½ ì¶œë ¥
        success_count = sum(1 for r in results if r.success)
        self.logger.info(f"\n{'='*60}")
        self.logger.info(f"ğŸ“Š ë°°ì¹˜ íƒì§€ ì™„ë£Œ")
        self.logger.info(f"{'='*60}")
        self.logger.info(f"ì´ ì´ë¯¸ì§€: {len(image_paths)}ê°œ")
        self.logger.info(f"ì„±ê³µ: {success_count}ê°œ")
        self.logger.info(f"ì‹¤íŒ¨: {len(image_paths) - success_count}ê°œ")
        self.logger.info(f"ì„±ê³µë¥ : {success_count/len(image_paths)*100:.1f}%")
        self.logger.info(f"{'='*60}\n")
        
        return results


# ========================================
# ğŸ¯ ì‚¬ìš© ì˜ˆì‹œ
# ========================================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    print("ğŸš ë“œë¡  íƒì§€ ë¶„ë¥˜ê¸° í…ŒìŠ¤íŠ¸\n")
    
    # ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
    classifier = DroneClassifier(
        model_path='runs/detect/drone_yolov8s/weights/best.pt',
        device=0,
        confidence_threshold=CONFIDENCE_THRESHOLD,
        required_count=REQUIRED_DETECTION_COUNT,  # ì •í™•íˆ 1ê°œì˜ ë“œë¡ ë§Œ íƒì§€ë˜ì–´ì•¼ í•¨
        save_outputs=True
    )
    '''
    # ========================================
    # í…ŒìŠ¤íŠ¸ 1: ë‹¨ì¼ ì´ë¯¸ì§€ íƒì§€
    # ========================================
    print("\n" + "="*60)
    print("í…ŒìŠ¤íŠ¸ 1: ë‹¨ì¼ ì´ë¯¸ì§€ íƒì§€")
    print("="*60)
    
    test_image_path = 'src/drone/dataset/test/images/example.jpg'
    
    if Path(test_image_path).exists():
        result = classifier.detect_from_file(
            test_image_path,
            visualize=True,
            save_json=True
        )
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š íƒì§€ ê²°ê³¼:")
        print(f"  - ì„±ê³µ: {result.success}")
        print(f"  - ë©”ì‹œì§€: {result.message}")
        print(f"  - íƒì§€ ê°œìˆ˜: {result.detection_count}/{result.required_count}")
        print(f"  - ì¶”ë¡  ì‹œê°„: {result.inference_time:.1f}ms")
        
        if result.detections:
            print(f"\nğŸ“ íƒì§€ëœ ê°ì²´:")
            for i, det in enumerate(result.detections, 1):
                print(f"  [{i}] {det.class_name}")
                print(f"      - ì‹ ë¢°ë„: {det.confidence:.3f}")
                print(f"      - ìœ„ì¹˜: {det.position_label} (ê·¸ë¦¬ë“œ: {det.position_grid})")
                print(f"      - ì¤‘ì‹¬: ({det.bbox.center_x:.1f}, {det.bbox.center_y:.1f})")
                print(f"      - í¬ê¸°: {det.bbox.width:.1f} x {det.bbox.height:.1f}")
        
        # ìœ„ì¹˜ ë°°ì—´ ì¶œë ¥
        positions = result.get_positions_array()
        print(f"\nğŸ“ ìœ„ì¹˜ ë°°ì—´ (ì¤‘ì‹¬ ì¢Œí‘œ):")
        print(positions)
        
        # ë°”ìš´ë”© ë°•ìŠ¤ ë°°ì—´ ì¶œë ¥
        bboxes = result.get_bboxes_array()
        print(f"\nğŸ“¦ ë°”ìš´ë”© ë°•ìŠ¤ ë°°ì—´:")
        print(bboxes)
    
    else:
        print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_image_path}")
    '''
    # ========================================
    # í…ŒìŠ¤íŠ¸ 2: ë°°ì¹˜ íƒì§€
    # ========================================
    print("\n" + "="*60)
    print("í…ŒìŠ¤íŠ¸ 2: ë°°ì¹˜ íƒì§€")
    print("="*60)
    
    test_dir = Path('src/drone/dataset/test/images')
    
    if test_dir.exists():
        image_files = list(test_dir.glob('*.jpg')) + list(test_dir.glob('*.png'))
        
        if image_files:
            # ìµœëŒ€ 5ê°œë§Œ í…ŒìŠ¤íŠ¸
            test_images = [str(p) for p in image_files[:37]]
            
            results = classifier.detect_batch(
                test_images,
                visualize=True,
                save_json=True
            )
        else:
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {test_dir}")
    else:
        print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_dir}")
    
    print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == '__main__':
    main()

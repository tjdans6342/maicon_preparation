import os
import cv2
import numpy as np
import sys
import glob
from target_geometry import recognize_rotated_h_marker_sift, transform_image_from_params
from second_target_geomentry import crop_rois_for_classification 

# ==============================================================================
# sencond_target_geomentry(process_batch_directory) ìƒìˆ˜ ì •ì˜: ì˜¥ìƒ ì¢Œí‘œ
# (ì´ ì¢Œí‘œëŠ” ì •ë ¬ëœ ì´ë¯¸ì§€ì— ëŒ€í•´ ê³ ì •ëœ ê°’ì…ë‹ˆë‹¤.)
# ==============================================================================

ROOFTOP_POSITIONS = {
    1: (1659.0, 955.0),
    2: (2023.0, 1038.0),
    3: (2593.0, 1048.0),
    4: (3373.0, 832.0),
    5: (2585.0, 1668.0),
    6: (1985.0, 1660.0),
    7: (829.0, 1956.0),
    8: (2021.0, 2160.0),
    9: (2935.0, 2178.0),
}

def extract_frames_from_video(video_path):
    """
    ë™ì˜ìƒì˜ ê²½ë¡œë¥¼ ì…ë ¥ë°›ì•„, ë™ì˜ìƒ íŒŒì¼ì´ ìœ„ì¹˜í•œ ë””ë ‰í† ë¦¬ì—
    ë™ì˜ìƒ ì´ë¦„ì˜ í´ë”ë¥¼ ìƒì„±í•˜ê³  ê° í”„ë ˆì„ì„ ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì¶”ì¶œí•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.
    """
    # 0. jpeg ì••ì¶•ë¥  ì„¤ì •
    compression_quality = 90 
    
    # 1. ë™ì˜ìƒ íŒŒì¼ ì—´ê¸°
    cap = cv2.VideoCapture(video_path)

    if not cap.isOpened():
        print(f"ì˜¤ë¥˜: ë™ì˜ìƒ íŒŒì¼ '{video_path}'ì„(ë¥¼) ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 2. ì¶œë ¥ í´ë” ì´ë¦„ ë° ê²½ë¡œ ì„¤ì • ìˆ˜ì •
    video_dir = os.path.dirname(video_path)
    base_name = os.path.splitext(os.path.basename(video_path))[0]
    
    # ì¶œë ¥ í´ë” ê²½ë¡œ ì„¤ì •
    output_dir = os.path.join(video_dir, base_name + "_frames")  # _frames ì ‘ë¯¸ì‚¬ ì¶”ê°€
    
    # ğŸ”¥ ê¸°ì¡´ì— íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ì‚­ì œ
    if os.path.isfile(output_dir):
        print(f"âš ï¸ ê²½ê³ : '{output_dir}'ì´(ê°€) íŒŒì¼ë¡œ ì¡´ì¬í•©ë‹ˆë‹¤. ì‚­ì œí•©ë‹ˆë‹¤.")
        os.remove(output_dir)

    # 3. ì¶œë ¥ í´ë” ìƒì„±
    try:
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            print(f"âœ… í´ë” ìƒì„± ì™„ë£Œ: {output_dir}")
        else:
            print(f"âš ï¸ ê²½ê³ : í´ë” '{output_dir}'ì´(ê°€) ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ê¸°ì¡´ íŒŒì¼ì— ë®ì–´ì“°ê±°ë‚˜ ì¶”ê°€ë©ë‹ˆë‹¤.")
    except OSError as e:
        print(f"âŒ ì˜¤ë¥˜: í´ë” ìƒì„± ì‹¤íŒ¨ - {e}")
        cap.release()
        return

    # 4. í”„ë ˆì„ ì¶”ì¶œ ë° ì €ì¥
    frame_count = 0
    print("í”„ë ˆì„ ì¶”ì¶œì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    print(f"ì´ í”„ë ˆì„ ìˆ˜: {total_frames}")

    while cap.isOpened():
        ret, frame = cap.read()

        if not ret:
            break

        # íŒŒì¼ ì´ë¦„ í˜•ì‹: frame_000000.jpg
        frame_filename = os.path.join(output_dir, f"frame_{frame_count:06d}.jpg")

        # í”„ë ˆì„ì„ JPG íŒŒì¼ë¡œ ì €ì¥
        cv2.imwrite(frame_filename, frame, [cv2.IMWRITE_JPEG_QUALITY, compression_quality])

        frame_count += 1
        
        # ì§„í–‰ë¥  í‘œì‹œ (10í”„ë ˆì„ë§ˆë‹¤)
        if frame_count % 10 == 0 or frame_count == total_frames:
            progress = (frame_count / total_frames) * 100 if total_frames > 0 else 0
            print(f"ì§„í–‰ ì¤‘: {frame_count}/{total_frames} ({progress:.1f}%)", end='\r')

    # 5. ì¢…ë£Œ ë° ì •ë¦¬
    cap.release()
    print(f"\n{'='*60}")
    print(f"âœ… ì¶”ì¶œ ì™„ë£Œ!")
    print(f"ì´ {frame_count}ê°œì˜ í”„ë ˆì„ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ì €ì¥ ìœ„ì¹˜: {output_dir}")
    print(f"{'='*60}")

def process_video_alignment(
    video_path: str,
    template_image_path: str,
    output_path: str,
    show_preview: bool = False,
    fps: int = None
) -> bool:
    """
    mp4 ë¹„ë””ì˜¤ íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ ê° í”„ë ˆì„ë§ˆë‹¤ H ë§ˆì»¤ë¥¼ ì¸ì‹í•˜ê³  í™”ë©´ ë³´ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        video_path (str): ì…ë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        template_image_path (str): H ë§ˆì»¤ í…œí”Œë¦¿ ì´ë¯¸ì§€ ê²½ë¡œ
        output_path (str): ì¶œë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        show_preview (bool): ì‹¤ì‹œê°„ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ ì—¬ë¶€
        fps (int): ì¶œë ¥ ë¹„ë””ì˜¤ FPS (Noneì´ë©´ ì›ë³¸ê³¼ ë™ì¼)
    
    Returns:
        bool: ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€
    """
    # 1. í…œí”Œë¦¿ ì´ë¯¸ì§€ ë¡œë“œ
    template_image = cv2.imread(template_image_path)
    if template_image is None:
        print(f"ì˜¤ë¥˜: í…œí”Œë¦¿ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {template_image_path}")
        return False
    
    # 2. ë¹„ë””ì˜¤ ìº¡ì²˜ ê°ì²´ ìƒì„±
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"ì˜¤ë¥˜: ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return False
    
    # 3. ë¹„ë””ì˜¤ ì†ì„± ê°€ì ¸ì˜¤ê¸°
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    original_fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    output_fps = fps if fps is not None else original_fps
    
    print(f"ë¹„ë””ì˜¤ ì •ë³´:")
    print(f"  - í•´ìƒë„: {frame_width}x{frame_height}")
    print(f"  - FPS: {original_fps:.2f}")
    print(f"  - ì´ í”„ë ˆì„ ìˆ˜: {total_frames}")
    print(f"  - ì¶œë ¥ FPS: {output_fps:.2f}")
    
    # 4. ë¹„ë””ì˜¤ ë¼ì´í„° ê°ì²´ ìƒì„±
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, output_fps, (frame_width, frame_height))
    
    if not out.isOpened():
        print(f"ì˜¤ë¥˜: ì¶œë ¥ ë¹„ë””ì˜¤ íŒŒì¼ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {output_path}")
        cap.release()
        return False
    
    # 5. í”„ë ˆì„ë³„ ì²˜ë¦¬
    frame_count = 0
    success_count = 0
    fail_count = 0
    
    print("\në¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘...")
    
    while True:
        ret, frame = cap.read()
        
        if not ret:
            break
        
        frame_count += 1
        
        # H ë§ˆì»¤ ì¸ì‹
        result = recognize_rotated_h_marker_sift(frame, template_image)
        
        if result is not None:
            # í™”ë©´ ë³´ì • ìˆ˜í–‰
            transformed_frame, _ = transform_image_from_params(frame, result)
            out.write(transformed_frame)
            success_count += 1
            
            # ì‹¤ì‹œê°„ ë¯¸ë¦¬ë³´ê¸°
            if show_preview:
                preview_frame = cv2.resize(transformed_frame, (960, 540))
                cv2.putText(preview_frame, f"Frame: {frame_count}/{total_frames}", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                cv2.imshow('Aligned Video Preview', preview_frame)
                
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    print("\nì‚¬ìš©ìì— ì˜í•´ ì²˜ë¦¬ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    break
        else:
            # H ë§ˆì»¤ ì¸ì‹ ì‹¤íŒ¨ ì‹œ ì›ë³¸ í”„ë ˆì„ ì‚¬ìš©
            out.write(frame)
            fail_count += 1
            
            if show_preview:
                preview_frame = cv2.resize(frame, (960, 540))
                cv2.putText(preview_frame, f"Frame: {frame_count}/{total_frames} (FAILED)", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                cv2.imshow('Aligned Video Preview', preview_frame)
                
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    print("\nì‚¬ìš©ìì— ì˜í•´ ì²˜ë¦¬ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    break
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        if frame_count % max(1, total_frames // 10) == 0:
            progress = (frame_count / total_frames) * 100
            print(f"ì§„í–‰ë¥ : {progress:.1f}% ({frame_count}/{total_frames} í”„ë ˆì„)")
    
    # 6. ë¦¬ì†ŒìŠ¤ í•´ì œ
    cap.release()
    out.release()
    
    if show_preview:
        cv2.destroyAllWindows()
    
    # 7. ê²°ê³¼ ì¶œë ¥
    print("\n=== ì²˜ë¦¬ ì™„ë£Œ ===")
    print(f"ì´ ì²˜ë¦¬ í”„ë ˆì„: {frame_count}")
    print(f"ì„±ê³µ: {success_count} ({success_count/frame_count*100:.1f}%)")
    print(f"ì‹¤íŒ¨: {fail_count} ({fail_count/frame_count*100:.1f}%)")
    print(f"ì¶œë ¥ íŒŒì¼: {output_path}")
    
    return True

def process_video_alignment_with_stabilization(
    video_path: str,
    template_image_path: str,
    output_path: str,
    show_preview: bool = False,
    fps: int = None,
    use_last_valid_transform: bool = True
) -> bool:
    """
    mp4 ë¹„ë””ì˜¤ íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ ê° í”„ë ˆì„ë§ˆë‹¤ H ë§ˆì»¤ë¥¼ ì¸ì‹í•˜ê³  í™”ë©´ ë³´ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    H ë§ˆì»¤ ì¸ì‹ ì‹¤íŒ¨ ì‹œ ì´ì „ í”„ë ˆì„ì˜ ë³€í™˜ íŒŒë¼ë¯¸í„°ë¥¼ ì¬ì‚¬ìš©í•˜ì—¬ ì•ˆì •ì ì¸ ì˜ìƒì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        video_path (str): ì…ë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        template_image_path (str): H ë§ˆì»¤ í…œí”Œë¦¿ ì´ë¯¸ì§€ ê²½ë¡œ
        output_path (str): ì¶œë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        show_preview (bool): ì‹¤ì‹œê°„ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ ì—¬ë¶€
        fps (int): ì¶œë ¥ ë¹„ë””ì˜¤ FPS (Noneì´ë©´ ì›ë³¸ê³¼ ë™ì¼)
        use_last_valid_transform (bool): ì¸ì‹ ì‹¤íŒ¨ ì‹œ ë§ˆì§€ë§‰ ìœ íš¨ ë³€í™˜ ì‚¬ìš© ì—¬ë¶€
    
    Returns:
        bool: ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€
    """
    # 1. í…œí”Œë¦¿ ì´ë¯¸ì§€ ë¡œë“œ
    template_image = cv2.imread(template_image_path)
    if template_image is None:
        print(f"ì˜¤ë¥˜: í…œí”Œë¦¿ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {template_image_path}")
        return False
    
    # 2. ë¹„ë””ì˜¤ ìº¡ì²˜ ê°ì²´ ìƒì„±
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"ì˜¤ë¥˜: ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return False
    
    # 3. ë¹„ë””ì˜¤ ì†ì„± ê°€ì ¸ì˜¤ê¸°
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    original_fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    output_fps = fps if fps is not None else original_fps
    
    print(f"ë¹„ë””ì˜¤ ì •ë³´:")
    print(f"  - í•´ìƒë„: {frame_width}x{frame_height}")
    print(f"  - FPS: {original_fps:.2f}")
    print(f"  - ì´ í”„ë ˆì„ ìˆ˜: {total_frames}")
    print(f"  - ì¶œë ¥ FPS: {output_fps:.2f}")
    
    # 4. ë¹„ë””ì˜¤ ë¼ì´í„° ê°ì²´ ìƒì„±
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, output_fps, (frame_width, frame_height))
    
    if not out.isOpened():
        print(f"ì˜¤ë¥˜: ì¶œë ¥ ë¹„ë””ì˜¤ íŒŒì¼ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {output_path}")
        cap.release()
        return False
    
    # 5. í”„ë ˆì„ë³„ ì²˜ë¦¬
    frame_count = 0
    success_count = 0
    fail_count = 0
    last_valid_params = None  # ë§ˆì§€ë§‰ìœ¼ë¡œ ì„±ê³µí•œ ë³€í™˜ íŒŒë¼ë¯¸í„° ì €ì¥
    
    print("\në¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘...")
    
    while True:
        ret, frame = cap.read()
        
        if not ret:
            break
        
        frame_count += 1
        
        # H ë§ˆì»¤ ì¸ì‹
        result = recognize_rotated_h_marker_sift(frame, template_image)
        
        if result is not None:
            # í™”ë©´ ë³´ì • ìˆ˜í–‰
            transformed_frame, _ = transform_image_from_params(frame, result)
            out.write(transformed_frame)
            success_count += 1
            last_valid_params = result  # ì„±ê³µí•œ íŒŒë¼ë¯¸í„° ì €ì¥
            status_text = "OK"
            status_color = (0, 255, 0)
            
        else:
            # H ë§ˆì»¤ ì¸ì‹ ì‹¤íŒ¨
            fail_count += 1
            
            if use_last_valid_transform and last_valid_params is not None:
                # ì´ì „ í”„ë ˆì„ì˜ ë³€í™˜ íŒŒë¼ë¯¸í„° ì‚¬ìš©
                transformed_frame, _ = transform_image_from_params(frame, last_valid_params)
                out.write(transformed_frame)
                status_text = "USING LAST"
                status_color = (0, 165, 255)  # ì£¼í™©ìƒ‰
            else:
                # ì›ë³¸ í”„ë ˆì„ ì‚¬ìš©
                out.write(frame)
                transformed_frame = frame
                status_text = "FAILED"
                status_color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰
        
        # ì‹¤ì‹œê°„ ë¯¸ë¦¬ë³´ê¸°
        if show_preview:
            preview_frame = cv2.resize(transformed_frame, (960, 540))
            cv2.putText(preview_frame, f"Frame: {frame_count}/{total_frames} [{status_text}]", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, status_color, 2)
            cv2.imshow('Aligned Video Preview', preview_frame)
            
            # 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¤‘ë‹¨
            if cv2.waitKey(1) & 0xFF == ord('q'):
                print("\nì‚¬ìš©ìì— ì˜í•´ ì²˜ë¦¬ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
                break
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        if frame_count % max(1, total_frames // 10) == 0:
            progress = (frame_count / total_frames) * 100
            print(f"ì§„í–‰ë¥ : {progress:.1f}% ({frame_count}/{total_frames} í”„ë ˆì„)")
    
    # 6. ë¦¬ì†ŒìŠ¤ í•´ì œ
    cap.release()
    out.release()
    
    if show_preview:
        cv2.destroyAllWindows()
    
    # 7. ê²°ê³¼ ì¶œë ¥
    print("\n=== ì²˜ë¦¬ ì™„ë£Œ ===")
    print(f"ì´ ì²˜ë¦¬ í”„ë ˆì„: {frame_count}")
    print(f"ì„±ê³µ: {success_count} ({success_count/frame_count*100:.1f}%)")
    print(f"ì‹¤íŒ¨: {fail_count} ({fail_count/frame_count*100:.1f}%)")
    print(f"ì¶œë ¥ íŒŒì¼: {output_path}")
    
    return True

def process_batch_directory(input_directory: str) -> None:
    """
    ì§€ì •ëœ ë””ë ‰í† ë¦¬ ë‚´ì˜ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ìˆœíšŒí•˜ë©° ROIë¥¼ ì˜ë¼ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        input_directory (str): ì •ë ¬ëœ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì´ ìœ„ì¹˜í•œ í´ë” ê²½ë¡œ.
    """
    
    # 1. ì…ë ¥ ë””ë ‰í† ë¦¬ ìœ íš¨ì„± ê²€ì‚¬
    if not os.path.isdir(input_directory):
        print(f"ì˜¤ë¥˜: ìœ íš¨í•˜ì§€ ì•Šì€ ë””ë ‰í† ë¦¬ ê²½ë¡œì…ë‹ˆë‹¤: {input_directory}")
        return

    # 2. ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ì—¬ê¸°ì„œëŠ” jpg png íŒŒì¼ë§Œ ì²˜ë¦¬)
    search_path = os.path.join(input_directory, '*.[jp][pn]g')
    image_files = glob.glob(search_path)

    if not image_files:
        print(f"ê²½ê³ : {input_directory} í´ë”ì—ì„œ ì²˜ë¦¬í•  png í˜¹ì€ jpg íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"--- ì´ {len(image_files)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤. ---")

    # 3. íŒŒì¼ ìˆœíšŒ ë° ì²˜ë¦¬
    for full_path in image_files:
        # íŒŒì¼ëª… ì¶”ì¶œ (í™•ì¥ì ì œì™¸) -> ì´ë¥¼ image_indexë¡œ ì‚¬ìš©
        filename_with_ext = os.path.basename(full_path)
        image_index = os.path.splitext(filename_with_ext)[0]
        
        print(f"\n[ì²˜ë¦¬ ì‹œì‘] íŒŒì¼: {filename_with_ext} (ì¸ë±ìŠ¤: {image_index})")
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(full_path)
        
        if image is None:
            print(f"ì˜¤ë¥˜: ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ - {full_path}. ê±´ë„ˆëœë‹ˆë‹¤.")
            continue
            
        # crop_rois_for_classification í•¨ìˆ˜ í˜¸ì¶œ
        try:
            crop_rois_for_classification(
                transformed_image=image,
                rooftop_positions=ROOFTOP_POSITIONS,
                image_index=image_index # íŒŒì¼ëª…ì„ ì¸ë±ìŠ¤ë¡œ ì‚¬ìš©
            )
            print(f"[ì²˜ë¦¬ ì™„ë£Œ] íŒŒì¼: {filename_with_ext}")
        except Exception as e:
            print(f"ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")


# ===== ë¹„ë””ì˜¤ ì •ë ¬ =====

'''
process_video_alignment_with_stabilization(
    video_path='src/drone/33.mkv',
    template_image_path='src/drone/h_template.png',
    output_path='src/drone/output_video_aligned_stable4.mkv',
    show_preview=True,
    fps=None,  # ì›ë³¸ FPS ìœ ì§€
    use_last_valid_transform=True  # ì´ì „ ë³€í™˜ íŒŒë¼ë¯¸í„° ì¬ì‚¬ìš©
)
'''
# --- ë™ì˜ìƒ ì»·íŒ… ---
# ì‚¬ìš© ì˜ˆì‹œ ê²½ë¡œë¥¼ ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ê²½ë¡œë¡œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.

video_file_path = "src/drone/33.mkv" 
extract_frames_from_video(video_file_path) 

# second_geomentryìš© í•¨ìˆ˜(í´ë”ì²˜ë¦¬)
# input_folder = 'src/drone/b_frames'
# process_batch_directory(input_folder)